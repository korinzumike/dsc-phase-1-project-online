{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This cell obtains United States Consumer Price Index (CPI) data from an online server.\n",
    "#  A function (defined in the present cell) that incorporates CPI data \n",
    "#  will later be used to make inflation adjustments on movie-related sales and budget figures.\n",
    "#\n",
    "#  MICHAEL COLLINS, 2020-09-15_0729_MDT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "#  Obtain monthly United States consumer price indices from \"inflationdata dot com\"\n",
    "#  and store them in pandas dataframe cpi_df.  \n",
    "source_url = 'https://inflationdata.com/Inflation/Consumer_Price_Index/HistoricalCPI.aspx?reloaded=true'\n",
    "cpi_df = pd.read_html(source_url)[0].drop(columns='Ave.')\n",
    "cpi_df.set_index('Year', drop=True, inplace=True, verify_integrity=False)\n",
    "\n",
    "year_to_cpi = np.round(cpi_df.mean(axis=1, skipna=True), decimals=6)\n",
    "\n",
    "def inflation_multiplier(from_year, into_year):\n",
    "    cpi_ratio = None\n",
    "    bomb = False\n",
    "    if not bomb:\n",
    "        from_cpi = None\n",
    "        try:\n",
    "            from_cpi = year_to_cpi[from_year]\n",
    "        except:\n",
    "            pass\n",
    "        if not isinstance(from_cpi, float):\n",
    "            bomb = True\n",
    "    if not bomb:\n",
    "        into_cpi = None\n",
    "        try:\n",
    "            into_cpi = year_to_cpi[into_year]\n",
    "        except:\n",
    "            pass\n",
    "        if not isinstance(into_cpi, float):\n",
    "            bomb = True\n",
    "    if not bomb:\n",
    "        cpi_ratio = np.round((into_cpi/from_cpi), decimals=6)\n",
    "    return cpi_ratio\n",
    "\n",
    "check_inflation_multiplier = True\n",
    "if not check_inflation_multiplier:\n",
    "    print(\"SKIPPING quality checks of inflation_multiplier function...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING quality checks of inflation_multiplier function...\")\n",
    "    print()\n",
    "\n",
    "    print(\"Annual values of the United States Consumer Price Index are\")\n",
    "    print(\"contained in the pandas series 'year_to_cpi', as follows:\")\n",
    "    display(year_to_cpi)\n",
    "\n",
    "    print(\"Here are the inflation adjustment factors one would apply to convert \")\n",
    "    print(\"the value of [Year YYYY dollars] into the value of [Year 2020 dollars]:\")\n",
    "    print()\n",
    "    from_years = list(range(1900,2031))\n",
    "    for j in [2020]:\n",
    "        for i in from_years:\n",
    "            factor_ij = inflation_multiplier(from_year=i, into_year=j)\n",
    "            print(\"inflation_multiplier(\" + str(i) + \", \" + str(j) + \") = \" + repr(factor_ij))\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This cell obtains film industry data directly from the website \"the-numbers.com\"\n",
    "#  and stores it in a dictionary called \"movieHandle_to_movieDoss\".\n",
    "#  \n",
    "#  A cleaned-up version of the above data is stored in another dictionary called\n",
    "#  \"eventHandle_to_eventDoss\".  That dictionary forms the basis of a pandas dataframe\n",
    "#  in a subsequent cell of this Notebook.\n",
    "#  \n",
    "#  MICHAEL COLLINS, 2020-09-11_2133_MDT\n",
    "\n",
    "import datetime\n",
    "from datetime import date\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import string\n",
    "from dateutil.parser import parse as dateparse\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import winsound\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: TN is an abbreviation for \"The Numbers\"; shorthand for 'the-numbers dot com'\n",
    "# Note: BOY is an abbreviation for \"Box-Office Year\"\n",
    "# Note: bgt is an abbreviation for the \"budget\" table\n",
    "# Note: tgy is an abbreviation for the \"top-grossing yearly\" table\n",
    "\n",
    "\n",
    "# Constants related to processing of generic calendar dates\n",
    "YEAR_PLAUSIBLE_FIRST = 1900\n",
    "YEAR_PLAUSIBLE_LAST = 2100\n",
    "DATE_PLAUSIBLE_FIRST = datetime.date(YEAR_PLAUSIBLE_FIRST,1,1)\n",
    "DATE_PLAUSIBLE_LAST = datetime.date(YEAR_PLAUSIBLE_LAST,12,31)\n",
    "WEEKDAY_MONDAY = 0\n",
    "WEEKDAY_TUESDAY = 1\n",
    "WEEKDAY_WEDNESDAY = 2\n",
    "WEEKDAY_THURSDAY = 3\n",
    "WEEKDAY_FRIDAY = 4\n",
    "WEEKDAY_SATURDAY = 5\n",
    "WEEKDAY_SUNDAY = 6\n",
    "\n",
    "# Constants related to \"the-numbers.com\" website\n",
    "TN_SALES_OMIT = [\",\", \"$\"]\n",
    "TN_SEATS_OMIT = [\",\"]\n",
    "TN_MAIN_URL = \"https://the-numbers.com\"\n",
    "TN_PARENT_FOLDER = \"./dayduh\"\n",
    "TN_MAIN_FOLDER = \"./dayduh/the-numbers\"\n",
    "TN_TOPGROSS_SUBFOLDER = \"/top-gross\"\n",
    "TN_TOPGROSS_SUBURL = \"/market/\"\n",
    "TN_TOPGROSS_URL_SUFFIX = \"/top-grossing-movies\"\n",
    "TN_BUDGETS_SUBFOLDER = \"/budgets\"\n",
    "TN_BUDGETS_SUBURL = \"/movie/budgets/\"\n",
    "TN_MOVIE_SUBFOLDER = \"/movie\"\n",
    "TN_MOVIE_SUBURL = \"/movie/\"\n",
    "TN_MOVIE_URL_SUFFIX = \"#tab=summary\"\n",
    "TN_DISTRIB_SUBURL = \"/market/distributor/\"\n",
    "TN_GENRE_SUBURL = \"/market/genre/\"\n",
    "TN_YEAR_CONSIDER_FIRST = 1977\n",
    "TN_YEAR_CONSIDER_LAST = 2020\n",
    "TN_GENRE_HANDLES = [\"_unknown_genre_\", \"Action\", \"Adventure\", \"Black-Comedy\", \"Comedy\", \"Concert-or-Performance\",\n",
    "                    \"Documentary\", \"Drama\", \"Horror\", \"Multiple-Genres\", \"Musical\", \"Reality\",\n",
    "                    \"Romantic-Comedy\", \"Thriller-or-Suspense\", \"Western\"]\n",
    "TN_GENRE_ABBRS = [\"(--none--)\", \"ACTION\", \"ADVENTURE\", \"BLK-COMEDY\", \"COMEDY\", \"CONCERT\",\n",
    "                  \"DOCUMENTARY\", \"DRAMA\", \"HORROR\", \"MULTI-GENRE\", \"MUSICAL\", \"REALITY\",\n",
    "                  \"ROM-COMEDY\", \"THRILLER\", \"WESTERN\"]\n",
    "\n",
    "# dictionaries that relate genre handles to genre abbreviations and vice versa\n",
    "TN_GENRE_INDICES = list(range(len(TN_GENRE_ABBRS)))\n",
    "gHandle_to_gAbbr = dict(zip(TN_GENRE_HANDLES, TN_GENRE_ABBRS))\n",
    "gAbbr_to_gHandle = dict(zip(TN_GENRE_ABBRS, TN_GENRE_HANDLES))\n",
    "gAbbr_to_gIndex = dict(zip(TN_GENRE_ABBRS, TN_GENRE_INDICES))\n",
    "gIndex_to_gAbbr = dict(zip(TN_GENRE_INDICES, TN_GENRE_ABBRS))\n",
    "\n",
    "# functions that allow commentary to be printed, \n",
    "# depending on value of COMMENTARY_LEVEL\n",
    "comm1 = lambda s: print(s) if COMMENTARY_LEVEL >= 1 else None\n",
    "comm2 = lambda s: print(s) if COMMENTARY_LEVEL >= 2 else None\n",
    "comm3 = lambda s: print(s) if COMMENTARY_LEVEL >= 3 else None\n",
    "comm4 = lambda s: print(s) if COMMENTARY_LEVEL >= 4 else None\n",
    "COMMENTARY_LEVEL = 3\n",
    "\n",
    "# This function returns the first calendar day of a given Box Office Year\n",
    "def boxOfficeYear_firstDay(boxOfficeYear):\n",
    "    # The first day of Box Office Year YYYY is \n",
    "    #     [the day AFTER the first Sunday in Calendar Year YYYY]\n",
    "    d = None\n",
    "    bomb = False\n",
    "    bomb = bomb or (not isinstance(boxOfficeYear, int))\n",
    "    bomb = bomb or (not boxOfficeYear >= YEAR_PLAUSIBLE_FIRST)\n",
    "    bomb = bomb or (not boxOfficeYear < YEAR_PLAUSIBLE_LAST)\n",
    "    if not bomb:\n",
    "        d = datetime.date(boxOfficeYear, 1, 1)\n",
    "        while not d.weekday() == WEEKDAY_SUNDAY:\n",
    "            d += datetime.timedelta(days=1)\n",
    "        while not d.weekday() == WEEKDAY_MONDAY:\n",
    "            d += datetime.timedelta(days=1)\n",
    "    return d\n",
    "\n",
    "# This function returns the last calendar day of a given Box Office Year\n",
    "def boxOfficeYear_lastDay(boxOfficeYear):\n",
    "    # The last day of Box Office Year YYYY is\n",
    "    #     [the first Sunday in Calendar Year (YYYY + 1)]\n",
    "    d = None\n",
    "    bomb = False\n",
    "    bomb = bomb or (not isinstance(boxOfficeYear, int))\n",
    "    bomb = bomb or (not boxOfficeYear >= YEAR_PLAUSIBLE_FIRST)\n",
    "    bomb = bomb or (not boxOfficeYear < YEAR_PLAUSIBLE_LAST)\n",
    "    if not bomb:\n",
    "        d = datetime.date(boxOfficeYear + 1, 1, 1)\n",
    "        while not d.weekday() == WEEKDAY_SUNDAY:\n",
    "            d += datetime.timedelta(days=1)\n",
    "    return d\n",
    "\n",
    "# This function returns the Box Office Year associated with a given calendar day\n",
    "def date_to_boxOfficeYear(d):\n",
    "    # The last day of Box Office Year YYYY is\n",
    "    #     [the first Sunday in Calendar Year (YYYY + 1)]\n",
    "    boxOfficeYear = None\n",
    "    bomb = False\n",
    "    bomb = bomb or (not isinstance(d, datetime.date))\n",
    "    bomb = bomb or (not d >= DATE_PLAUSIBLE_FIRST)\n",
    "    bomb = bomb or (not d <= DATE_PLAUSIBLE_LAST)\n",
    "    if not bomb:\n",
    "        d_calendar_year = d.year\n",
    "        mainBOY_firstDay = boxOfficeYear_firstDay(d_calendar_year)\n",
    "        bomb = not isinstance(mainBOY_firstDay, datetime.date)\n",
    "    if not bomb:\n",
    "        if d < mainBOY_firstDay:\n",
    "            boxOfficeYear = d_calendar_year - 1\n",
    "        else:\n",
    "            boxOfficeYear = d_calendar_year\n",
    "    return boxOfficeYear\n",
    "\n",
    "\n",
    "# This function makes two audible beeps.\n",
    "# An audible signal, suitably implemented, can alert the user\n",
    "# when (for example) a long-running computational task is completed.\n",
    "def make_beeps():\n",
    "    Freq = 440 # Set Frequency To 440 Hertz\n",
    "    Dur = 500 # Set Duration To 500 ms == 0.5 second\n",
    "    winsound.Beep(Freq,Dur)\n",
    "    Freq = 880 # Set Frequency To 880 Hertz\n",
    "    Dur = 500 # Set Duration To 500 ms == 0.5 second\n",
    "    winsound.Beep(Freq,Dur)\n",
    "    return\n",
    "\n",
    "# extract movie handle from movie href\n",
    "def get_movie_handle(href):\n",
    "    def remove_mh_prefix(v):\n",
    "        return v[len(TN_MOVIE_SUBURL):] if v.startswith(TN_MOVIE_SUBURL) else v\n",
    "    def remove_mh_suffix(v):\n",
    "        return v[:-len(TN_MOVIE_URL_SUFFIX)] if v.endswith(TN_MOVIE_URL_SUFFIX) else v\n",
    "    return remove_mh_suffix(remove_mh_prefix(href))\n",
    "\n",
    "# extract distributor handle from distributor href\n",
    "def get_distrib_handle(v):\n",
    "    return v[len(TN_DISTRIB_SUBURL):] if v.startswith(TN_DISTRIB_SUBURL) else v\n",
    "\n",
    "# extract genre handle from genre href\n",
    "def get_genre_handle(v):\n",
    "    return v[len(TN_GENRE_SUBURL):] if v.startswith(TN_GENRE_SUBURL) else v\n",
    "\n",
    "def tnURL_movieWebsite(movie_handle, as_path=False):\n",
    "    bomb = False\n",
    "    bomb = bomb or (not isinstance(movie_handle, str))\n",
    "    bomb = bomb or (not len(movie_handle) >= 1)\n",
    "    f_result = None\n",
    "    if not bomb:\n",
    "        path_ref = \"/\" + movie_handle + \".html\"\n",
    "        url_ref = movie_handle + TN_MOVIE_URL_SUFFIX\n",
    "        if as_path:\n",
    "            f_result = TN_MAIN_FOLDER + TN_MOVIE_SUBFOLDER + path_ref\n",
    "        else:\n",
    "            f_result = TN_MAIN_URL + TN_MOVIE_SUBURL + url_ref\n",
    "    return f_result\n",
    "\n",
    "def tnURL_budgets_glob(start_rank=1, as_path=False):\n",
    "    bomb = False\n",
    "    bomb = bomb or (not isinstance(start_rank, int))\n",
    "    bomb = bomb or (not start_rank >= 1)\n",
    "    f_result = None\n",
    "    if not bomb:\n",
    "        page, j = divmod(start_rank, 100)\n",
    "        if page > 0:\n",
    "            i_rank = (100 * page) + 1\n",
    "            s_rank = str(i_rank).zfill(4)\n",
    "            path_ref = \"/all_\" + s_rank + \".html\"\n",
    "            url_ref = \"all/\" + s_rank\n",
    "        else:\n",
    "            path_ref = \"/all_0001.html\"\n",
    "            url_ref = \"all/1\"\n",
    "        if as_path:\n",
    "            f_result = TN_MAIN_FOLDER + TN_BUDGETS_SUBFOLDER + path_ref \n",
    "        else:\n",
    "            f_result = TN_MAIN_URL + TN_BUDGETS_SUBURL + url_ref\n",
    "    return f_result\n",
    "\n",
    "def tnURL_topGross_byYear(box_office_year, as_path=False):\n",
    "    bomb = False\n",
    "    bomb = bomb or (not isinstance(box_office_year, int))\n",
    "    bomb = bomb or (not box_office_year >= TN_YEAR_CONSIDER_FIRST)\n",
    "    bomb = bomb or (not box_office_year <= TN_YEAR_CONSIDER_LAST)\n",
    "    f_result = None\n",
    "    if not bomb:\n",
    "        path_ref = \"/top-grossing-movies_\" + str(box_office_year) + \".html\"\n",
    "        url_ref = str(box_office_year) + \"/top-grossing-movies\"\n",
    "        if as_path:\n",
    "            f_result = TN_MAIN_FOLDER + TN_TOPGROSS_SUBFOLDER + path_ref \n",
    "        else:\n",
    "            f_result = TN_MAIN_URL + TN_TOPGROSS_SUBURL + url_ref\n",
    "    return f_result\n",
    "\n",
    "\n",
    "def local_curated_folder_exists(desired_folder):\n",
    "    result = False\n",
    "    \n",
    "    still_going = True\n",
    "    while still_going:\n",
    "        # Check whether a locally-curated version of the desired webContent already exists.\n",
    "        try:\n",
    "            old_folder = pathlib.Path(desired_folder)\n",
    "            old_folder_exists = old_folder.exists()\n",
    "        except:\n",
    "            print(\"Issue: could not determine whether local folder {\" + desired_folder + \"} already exists.\")\n",
    "            still_going = False\n",
    "            break\n",
    "        if old_folder_exists:\n",
    "            # This is the most-preferred outcome.  The desired folder already exists.\n",
    "            still_going = False\n",
    "            result = True\n",
    "            break\n",
    "            \n",
    "        # At this point, the desired local folder does NOT already exist.\n",
    "        \n",
    "        # Try to create the desired local folder.\n",
    "        try:\n",
    "            new_folder = pathlib.Path(desired_folder).mkdir(mode=0o777, parents=True, exist_ok=False)\n",
    "        except:\n",
    "            print(\"Issue: could not create new local folder {\" + desired_folder + \"}.\")\n",
    "            still_going = False\n",
    "            break\n",
    "            \n",
    "        # At this point, we THINK a new instance of the desired local folder was just created.\n",
    "        # Make sure it is actually there.\n",
    "        try:\n",
    "            new_folder = pathlib.Path(desired_folder)\n",
    "            new_folder_exists = new_folder.exists()\n",
    "        except:\n",
    "            print(\"Issue: could not determine whether **newly-created** local folder {\" + desired_folder + \"} already exists.\")\n",
    "            still_going = False\n",
    "            break\n",
    "        if new_folder_exists:\n",
    "            # This is the second-most-preferred outcome.  The desired folder was created.\n",
    "            still_going = False\n",
    "            result = True\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def local_curated_file_exists(webContent_local_path, webContent_url):\n",
    "    result = False\n",
    "    \n",
    "    still_going = True\n",
    "    while still_going:\n",
    "        \n",
    "        # Check whether a locally-curated version of the desired webContent already exists.\n",
    "        try:\n",
    "            old_file = pathlib.Path(webContent_local_path)\n",
    "            old_file_exists = old_file.exists()\n",
    "        except:\n",
    "            print(\"Issue: could not determine whether local file {\" + webContent_local_path + \"} already exists.\")\n",
    "            still_going = False\n",
    "            break\n",
    "        if old_file_exists:\n",
    "            # This is the most favorable outcome.  A locally curated version of the webContent was found.\n",
    "            still_going = False\n",
    "            result = True\n",
    "            break\n",
    "\n",
    "        # Download the webContent via webContent_url\n",
    "        try:\n",
    "            r = requests.get(webContent_url)\n",
    "            webContent = r.content\n",
    "        except:\n",
    "            print(\"Issue: webContent was not obtained from URL {\" + webContent_url + \"}.\")\n",
    "            still_going = False\n",
    "            break\n",
    "            \n",
    "        # Save the webContent as a locally-curated file.\n",
    "        try:\n",
    "            with open(webContent_local_path, 'wb') as f:\n",
    "                f.write(webContent)\n",
    "        except:\n",
    "            print(\"Issue: webContent was not written to file {\" + webContent_local_path + \"}.\")\n",
    "            still_going = False\n",
    "            break\n",
    "            \n",
    "        # Confirm that the (brand-new) locally-curated file exists\n",
    "        new_file_exists = False\n",
    "        try:\n",
    "            new_file = pathlib.Path(webContent_local_path)\n",
    "            new_file_exists = new_file.exists()\n",
    "        except:\n",
    "            print(\"Issue: after webContent was stored locally, could not determine \" + \n",
    "                  \"whether the local copy {\" + webContent_local_path + \"} exists.\")\n",
    "            still_going = False\n",
    "            break\n",
    "        if not new_file_exists:\n",
    "            print(\"Issue: after webContent was stored locally, the local copy {\" + \n",
    "                  webContent_local_path + \"} does not exist.\")\n",
    "            still_going = False\n",
    "            break\n",
    "        \n",
    "        # Confirm that the (brand-new) locally-curated file can be read\n",
    "        try:\n",
    "            with open(webContent_local_path, 'rb') as g:\n",
    "                localContent = g.read()\n",
    "        except:\n",
    "            print(\"Issue: after webContent was stored locally, the local copy {\" + \n",
    "                  webContent_local_path + \"} exists, but could not be read.\")\n",
    "            still_going = False\n",
    "            break\n",
    "            \n",
    "        # Confirm that the archived version of the webContent \n",
    "        # is exactly the same as the downloaded version of the webContent\n",
    "        if not localContent == webContent:\n",
    "            print(\"Issue: after webContent was stored locally, the local version \" + \n",
    "                  \"found at {\" + webContent_local_path + \"} is NOT an exact replica of the \" +\n",
    "                  \"webContent that was downloaded from {\" + webContent_url + \"}.\")\n",
    "            still_going = False\n",
    "            break\n",
    "        \n",
    "        # The archived webContent is an exact replica of the downloaded webContent\n",
    "        still_going = False\n",
    "        result = True\n",
    "        print(\"An exact replica of the webContent at {\" + webContent_url + \n",
    "              \"} was stored in local file {\" + webContent_local_path + \"}.\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#   IN THIS SECTION,\n",
    "#       QUALITY CHECKS ON THE FUNCTIONS DEFINED ABOVE\n",
    "#       MAY OPTIONALLY BE PERFORMED\n",
    "#       AT THE DISCRETION OF THE USER\n",
    "#       BY SETTING THE \"check_????\" FLAGS TO True or False, ACCORDINGLY\n",
    "# ==============================================================================\n",
    "\n",
    "check_genre_dicts = True\n",
    "if not check_genre_dicts:\n",
    "    print(\"SKIPPING quality checks of genre-related dictionaries...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING quality checks of genre-related dictionaries...\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Quality check of gHandle_to_gAbbr...\")\n",
    "    for i, k in enumerate(TN_GENRE_HANDLES):\n",
    "        def check_same(v1, v2):\n",
    "            return \"PASS\" if (v1 == v2) else \"FAIL\"\n",
    "        v_expected = TN_GENRE_ABBRS[i]\n",
    "        v_lookup = \"--absent--\"\n",
    "        try:\n",
    "            v_lookup = gHandle_to_gAbbr[k]\n",
    "        except:\n",
    "            v_lookup = None\n",
    "        print(\"i=\" + str(i) + \", key=\" + repr(k) + \", v_expected=\" + repr(v_expected) +\n",
    "              \", v_lookup=\" + repr(v_lookup) + \", status=\" + check_same(v_expected, v_lookup))\n",
    "    print()\n",
    "        \n",
    "    print(\"Quality check of gAbbr_to_gHandle...\")\n",
    "    for i, k in enumerate(TN_GENRE_ABBRS):\n",
    "        def check_same(v1, v2):\n",
    "            return \"PASS\" if (v1 == v2) else \"FAIL\"\n",
    "        v_expected = TN_GENRE_HANDLES[i]\n",
    "        v_lookup = \"--absent--\"\n",
    "        try:\n",
    "            v_lookup = gAbbr_to_gHandle[k]\n",
    "        except:\n",
    "            v_lookup = None\n",
    "        print(\"i=\" + str(i) + \", key=\" + repr(k) + \", v_expected=\" + repr(v_expected) +\n",
    "              \", v_lookup=\" + repr(v_lookup) + \", status=\" + check_same(v_expected, v_lookup))\n",
    "    print()\n",
    "\n",
    "check_boxOfficeYear_date_functions = True\n",
    "if not check_boxOfficeYear_date_functions:\n",
    "    print(\"SKIPPING quality checks of boxOfficeYear-related date functions...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING quality checks of boxOfficeYear-related date functions...\")\n",
    "    print()\n",
    "\n",
    "    print(\"Calculating the beginning and ending dates of various Box Office Years...\")\n",
    "    print()\n",
    "    BOYs = [y for y in range(TN_YEAR_CONSIDER_FIRST, TN_YEAR_CONSIDER_LAST + 1)]\n",
    "    for BOY in BOYs:\n",
    "        day_first = boxOfficeYear_firstDay(BOY)\n",
    "        day_last = boxOfficeYear_lastDay(BOY)\n",
    "\n",
    "        print(\"BOY = {\" + str(BOY) + \"}, starts \" + \n",
    "              day_first.strftime(\"%a\") + \" {\" + \n",
    "              repr(day_first) + \"}, ends \" + \n",
    "              day_last.strftime(\"%a\") + \" {\" + \n",
    "              repr(day_last) + \"}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Verifying that the calculated boxOfficeYear for each individual day\")\n",
    "    print(\"that occurs DURING that particular boxOfficeYear is in fact the\")\n",
    "    print(\"known (prescribed) boxOfficeYear...\")\n",
    "    print()\n",
    "    BOYs = [y for y in range(1915,2032)]\n",
    "    for BOY in BOYs:\n",
    "        day_first = boxOfficeYear_firstDay(BOY)\n",
    "        day_last = boxOfficeYear_lastDay(BOY)\n",
    "        d = day_first\n",
    "        BOY_num_days_agree = 0\n",
    "        BOY_num_days_disagree = 0\n",
    "        BOY_list_days_disagree = []\n",
    "        while d <= day_last:\n",
    "            calc_BOY = date_to_boxOfficeYear(d)\n",
    "            if calc_BOY == BOY:\n",
    "                BOY_num_days_agree += 1\n",
    "            else:\n",
    "                BOY_num_days_disagree += 1\n",
    "                BOY_list_days_disagree.append(d)\n",
    "                \n",
    "            d += datetime.timedelta(days=1)\n",
    "        if BOY_num_days_disagree > 0:\n",
    "            print(\"BOX OFFICE YEAR \" + str(BOY) + \":\")\n",
    "            print(\"     \" + str(BOY_num_days_disagree) + \" days DISAGREE, as follow:\")\n",
    "            for d in BOY_list_days_disagree:\n",
    "                print(\"     \" + repr(d))\n",
    "    print()\n",
    "\n",
    "check_tnURL_budgets_glob = False\n",
    "if not check_tnURL_budgets_glob:\n",
    "    print(\"SKIPPING quality checks of function tnURL_budgets_glob...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING quality checks of function tnURL_budgets_glob...\")\n",
    "    print()\n",
    "    start_nums = sorted([random.randint(-100, 3001) for k in range(100)])\n",
    "    for i in start_nums:\n",
    "        print(\"i = {\" + str(i) + \"}: \")\n",
    "        print(\"     budgets_glob_path = \" + repr(tnURL_budgets_glob(i, as_path=True)))\n",
    "        print(\"     budgets_glob_url  = \" + repr(tnURL_budgets_glob(i)))\n",
    "    print()  \n",
    "\n",
    "check_tnURL_topGross_byYear = False\n",
    "if not check_tnURL_topGross_byYear:\n",
    "    print(\"SKIPPING quality checks of function tnURL_topGross_byYear...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING quality checks of function tnURL_topGross_byYear...\")\n",
    "    print()\n",
    "    box_office_years = [iBOY for iBOY in range(1960,2031)]\n",
    "    for iBOY in box_office_years:\n",
    "        print(\"boxOfficeYear = {\" + str(iBOY) + \"}: \")\n",
    "        print(\"     topGross_byYear_path = \" + repr(tnURL_topGross_byYear(iBOY, as_path=True)))\n",
    "        print(\"     topGross_byYear_url  = \" + repr(tnURL_topGross_byYear(iBOY)))\n",
    "    print()  \n",
    "    \n",
    "check_tnURL_movieWebsite = False\n",
    "if not check_tnURL_movieWebsite:\n",
    "    print(\"SKIPPING quality checks of function tnURL_movieWebsite...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING quality checks of function tnURL_movieWebsite...\")\n",
    "    print()\n",
    "    # Here are some example movie handles.  This is for testing the\n",
    "    # operation of the tnURL_movieWebsite function\n",
    "    movie_handles = ['(Untitled)', '10', '10-000-B-C', '10-Cloverfield-Lane', '10-Days-in-a-Madhouse', \n",
    "                     '10-Questions-for-the-Dalai-Lama', '10-Things-I-Hate-About-You', '10-to-Midnight', \n",
    "                     '10-Years', '100-Acres-of-Hell', '100-Arabica', '100-Bloody-Acres', '1001-Grams', \n",
    "                     '101-Dalmatians-(1961)', '101-Dalmatians-(1996)', '101-ReykjavA-k', '102-Dalmatians', \n",
    "                     '102-Not-Out-(India)', '10E', '10th-and-Wolf', '11-09-01-September-11', '11-11-11', \n",
    "                     '11-14', '11th-Hour', '12-(2009-Russian-Federation)', '12-Angry-Men', '12-in-a-Box', \n",
    "                     '12-jours-(France-2017)', '12-Monkeys', '12-O-Clock-Boys', '12-Rounds', '12-Strong', \n",
    "                     '12-Years-a-Slave', '120-battements-par-minute-(France)-(BPM-Beats-Per-Minute)', \n",
    "                     '127-Hours', '127-Hours-(2010)', '13-Going-On-30', \n",
    "                     '13-Hours-The-Secret-Soldiers-of-Benghazi', '13-Months-of-Sunshine', '13-Sins', \n",
    "                     '13-Tzameti', '13B', '13th-Warrior-The', '1408', '1492-Conquest-of-Paradise', \n",
    "                     '15', '15-17-to-Paris-The', '15-fevrier-1839', '15-Minutes', '16-Blocks', \n",
    "                     '16-to-Life', '1612', '17-Again', '17-filles-(France)', '1776', '18-Again', \n",
    "                     '18-ans-apres', '180-South', '1898-Los-ultimos-de-Filipinas-(Spain)', '1915', \n",
    "                     '1917-(2019)', '1941', '1945-(Hungary)', '1969', '1981', '1982', \n",
    "                     '1999-Cannes-Intl-Adv-Festival', '2-13', '2-22-(2017)', '2-automnes-3-hivers', \n",
    "                     '2-Days-in-New-York', '2-Days-In-The-Valley', '2-Fast-2-Furious', '2-For-the-Money', \n",
    "                     '2-Guns', '2-Manner-2-Frauen-4-Probleme', '2-ou-3-choses-que-je-sais-d-elle', \n",
    "                     '2-States', '20-centimetros', '20-Dates', '20-Feet-From-Stardom', '200-Cartas', \n",
    "                     '200-Cigarettes', '20000-Days-on-Earth', '20000-Leagues-Under-the-Sea-(1916)', \n",
    "                     '20000-Leagues-Under-the-Sea-(1954)', '2001-A-Space-Odyssey', \n",
    "                     '2005-Academy-Award-Nominated-Short-Films-The', \n",
    "                     '2006-Academy-Award-Nominated-Short-Films', '2009-Oscar-Shorts', '2010', \n",
    "                     '2010-Oscar-Shorts', '2011-Oscar-Shorts', '2012', '2012-Oscar-Shorts', \n",
    "                     '2012-Time-for-Change', '2013-Oscar-Shorts', '2014-Oscar-Shorts', '2015-Oscar-Shorts', \n",
    "                     '2016-Obama-s-America']\n",
    "    for mh in movie_handles[0:10]:\n",
    "        movieWebsite_path = tnURL_movieWebsite(mh, as_path=True)\n",
    "        movieWebsite_url  = tnURL_movieWebsite(mh)\n",
    "        \n",
    "        print(\"movie_handle = {\" + mh + \"}: \")\n",
    "        print(\"     movieWebsite_path = \" + repr(movieWebsite_path))\n",
    "        print(\"     movieWebsite_url  = \" + repr(movieWebsite_url))\n",
    "        print()  \n",
    "        \n",
    "        # Now store a local version of the movie's web content\n",
    "\n",
    "        if not local_curated_file_exists(movieWebsite_path, movieWebsite_url):\n",
    "            print(\"Issue: Attempt to store webContent at URL {\" + \n",
    "                  movieWebsite_url + \"} as local file {\" + \n",
    "                  movieWebsite_path + \"} has failed.\")\n",
    "            print()\n",
    "\n",
    "            \n",
    "\n",
    "# ==============================================================================\n",
    "#   IN THIS SECTION,\n",
    "#       LOCAL FOLDERS (FOR CACHED LOCAL VERSIONS OF WEB CONTENT) ARE CREATED, AS NEEDED.\n",
    "#\n",
    "# ==============================================================================\n",
    "            \n",
    "issues_found = True\n",
    "if local_curated_folder_exists(TN_PARENT_FOLDER):\n",
    "    if local_curated_folder_exists(TN_MAIN_FOLDER):\n",
    "        if local_curated_folder_exists(TN_MAIN_FOLDER + TN_MOVIE_SUBFOLDER):\n",
    "            if local_curated_folder_exists(TN_MAIN_FOLDER + TN_BUDGETS_SUBFOLDER):\n",
    "                if local_curated_folder_exists(TN_MAIN_FOLDER + TN_TOPGROSS_SUBFOLDER):\n",
    "                    issues_found = False  \n",
    "                else:\n",
    "                    print(\"Issue: Attempt to create local folder {\" + \n",
    "                          TN_MAIN_FOLDER + TN_TOPGROSS_SUBFOLDER + \"} has failed.\")\n",
    "            else:\n",
    "                print(\"Issue: Attempt to create local folder {\" + \n",
    "                      TN_MAIN_FOLDER + TN_BUDGETS_SUBFOLDER + \"} has failed.\")\n",
    "        else:\n",
    "            print(\"Issue: Attempt to create local folder {\" + \n",
    "                  TN_MAIN_FOLDER + TN_MOVIE_SUBFOLDER + \"} has failed.\")\n",
    "    else:\n",
    "        print(\"Issue: Attempt to create local folder {\" + \n",
    "              TN_MAIN_FOLDER + \"} has failed.\")\n",
    "else:\n",
    "    print(\"Issue: Attempt to create local folder {\" + \n",
    "          TN_PARENT_FOLDER + \"} has failed.\")\n",
    "if issues_found:\n",
    "    # Pitch a fit.\n",
    "    print(\"Unable to cache webContent in local data curation folders.\")\n",
    "    print()\n",
    "    print(\"Purposely Terminating program execution, now.\")\n",
    "    assert False\n",
    "print(\"All desired folders for local curation of webContent were verified to be present.\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#   IN THIS SECTION,\n",
    "#       HARVESTING OF DATA FROM \"the-numbers dot com\" IS PERFORMED.\n",
    "#\n",
    "#       EACH MODE OF DATA HARVEST OPERATION\n",
    "#       MAY OPTIONALLY BE PERFORMED AT THE DISCRETION OF THE USER\n",
    "#       BY SETTING \"harvest_????\" FLAGS TO True OR False, ACCORDINGLY\n",
    "# ==============================================================================\n",
    "\n",
    "movieHandle_to_movieDoss = dict()\n",
    "distribHandle_to_distribDoss = dict()\n",
    "genreHandle_to_genreDoss = dict()\n",
    "\n",
    "bgt_rows_cumulative = 0\n",
    "tgy_rows_cumulative = 0\n",
    "\n",
    "\n",
    "harvest_bgt = True\n",
    "if not harvest_bgt:\n",
    "    print(\"SKIPPING harvest of [movies sorted by production budget]...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING harvest of [movies sorted by production budget]...\")\n",
    "    print()\n",
    "    \n",
    "    COMMENTARY_LEVEL = 2\n",
    "    bgt_rank_nextup = 1\n",
    "    bgt_rank_max = 9999\n",
    "    \n",
    "    comm1(\"============================================\")\n",
    "    comm1(\"   HARVESTING DATA FROM [MULTI-PAGE TABLE\")\n",
    "    comm1(\"   OF MOVIES RANKED BY PRODUCTION BUDGET]\")\n",
    "    comm1(\"============================================\")\n",
    "    comm1(\"\")\n",
    "    \n",
    "    quite_done = False\n",
    "    issues_found = True\n",
    "    while not quite_done:\n",
    "\n",
    "        bgt_glob_path = tnURL_budgets_glob(bgt_rank_nextup, as_path=True)\n",
    "        bgt_glob_url = tnURL_budgets_glob(bgt_rank_nextup)\n",
    "\n",
    "        comm4(bgt_glob_path)\n",
    "        comm4(\"\")\n",
    "        comm4(bgt_glob_url)\n",
    "        comm4(\"\")\n",
    "\n",
    "        if not local_curated_file_exists(bgt_glob_path, bgt_glob_url):\n",
    "            print(\"Issue: Attempt to store webContent at URL {\" + \n",
    "                  bgt_glob_url + \"} as local file {\" + \n",
    "                  bgt_glob_path + \"} has failed.\")\n",
    "            quite_done = True\n",
    "            break\n",
    "            \n",
    "        comm3(\"Getting HTML content from local file {\" + bgt_glob_path + \"} as soup...\")\n",
    "        comm3(\"\")\n",
    "        try:\n",
    "            with open(bgt_glob_path, 'rb') as g:\n",
    "                localContent = g.read()\n",
    "                soup = BeautifulSoup(\n",
    "                    localContent, \"html.parser\")\n",
    "        except:\n",
    "            print(\"Issue: Attempt retrieve curated webContent from local file {\" + \n",
    "                  bgt_glob_path + \"} has failed.\")\n",
    "            quite_done = True\n",
    "            break\n",
    "\n",
    "        comm4(\"Identifying tables in soup...\")\n",
    "        comm4(\"\")\n",
    "\n",
    "        soup_tables = soup.find_all(\"table\")\n",
    "\n",
    "        num_soup_tables = len(soup_tables)\n",
    "        comm4(\"num_soup_tables = \" + repr(num_soup_tables))\n",
    "        comm4(\"\")\n",
    "\n",
    "        if num_soup_tables == 0:\n",
    "            print(\"ISSUE: No tables were identified in soup.\")\n",
    "            print(\"Did not obtain tabular data from file {\" + bgt_glob_path + \"}.\")\n",
    "            quite_done = True\n",
    "            break\n",
    "\n",
    "        if num_soup_tables > 1:\n",
    "            comm4(\"A total of \" + str(num_soup_tables) + \" tables were identified in soup.\")\n",
    "            comm4(\"Only the first table will be examined.\")\n",
    "        table = soup_tables[0]\n",
    "\n",
    "        # Look for the header row, then extract headers from it, if found.\n",
    "        comm4(\"Now processing the HEADER ROW...\")\n",
    "        comm4(\"\")\n",
    "        contains_th = lambda tag: len(tag.find_all(\"th\")) > 0        \n",
    "\n",
    "        tr_list = [tr for tr in table.find_all(\"tr\", recursive=False) if contains_th(tr)]\n",
    "\n",
    "        num_header_rows = len(tr_list)\n",
    "        comm4(\"num_header_rows = \" + repr(num_header_rows))\n",
    "        comm4(\"\")\n",
    "        if num_header_rows == 0:\n",
    "            print(\"ISSUE: No header row was identified in the table.\")\n",
    "            quite_done = True\n",
    "            break\n",
    "        if num_header_rows > 1:\n",
    "            comm4(\"A total of \" + str(num_header_rows) + \" header rows were identified in the table.\")\n",
    "            comm4(\"Only the first header row will be examined.\")\n",
    "            comm4(\"\")\n",
    "\n",
    "        original_headers = [\" \".join(th.strings) for th in tr_list[0].find_all(\"th\")]\n",
    "\n",
    "        table_num_columns = len(original_headers)\n",
    "        comm4(\"table_num_columns = \" + repr(table_num_columns))\n",
    "        comm4(\"\")\n",
    "        if table_num_columns == 0:\n",
    "            print(\"ISSUE: No column headers were found in the header row.\")\n",
    "            quite_done = True\n",
    "            break\n",
    "\n",
    "        comm4(\"The following column headers were identified:\")\n",
    "        comm4(repr(original_headers))\n",
    "        comm4(\"\")\n",
    "        \n",
    "        # correlate original headers with column indices\n",
    "        colHeader_to_j = dict(zip(original_headers, [j for j in range(table_num_columns)]))\n",
    "        j_MOVIE = colHeader_to_j['Movie']\n",
    "        j_RELEASE_DATE = colHeader_to_j['Release Date']\n",
    "        j_PRODUCTION_BUDGET = colHeader_to_j['Production Budget']\n",
    "        j_DOMESTIC_GROSS = colHeader_to_j['Domestic Gross']\n",
    "        j_WORLDWIDE_GROSS = colHeader_to_j['Worldwide Gross']\n",
    "\n",
    "        comm4(\"Now processing the DATA ROWS...\")\n",
    "        comm4(\"\")\n",
    "\n",
    "        contains_a = lambda tag: len(tag.find_all(\"a\")) > 0\n",
    "        contains_td = lambda tag: len(tag.find_all(\"td\")) > 0        \n",
    "        tr_list = [tr for tr in table.find_all(\"tr\", recursive=False) if contains_a(tr) & contains_td(tr)]\n",
    "\n",
    "        num_data_rows = len(tr_list)\n",
    "        comm4(\"num_data_rows = \" + repr(num_data_rows))\n",
    "        comm4(\"\")\n",
    "        if num_data_rows == 0:\n",
    "            print(\"ISSUE: No data rows were identified in the table.\")\n",
    "            quite_done = True\n",
    "            break\n",
    "\n",
    "        for i, tr in enumerate(tr_list):\n",
    "            td_list = tr.find_all(\"td\")\n",
    "\n",
    "            num_td = len(td_list)\n",
    "            if num_td < table_num_columns:\n",
    "                print(\"ISSUE: Only \"+ str(num_td) + \" data elements were identified \" +\n",
    "                      \"in the data row whose index is {\" + str(i) + \"} .\")\n",
    "                print(\"Each data row in the table was expected to have {\" + str(table_num_columns) + \"} columns .\")\n",
    "                quite_done = True\n",
    "                break\n",
    "            \n",
    "            for tda in [td_list[j_MOVIE].a]:\n",
    "                if tda is None:\n",
    "                    film_handle = None\n",
    "                else:\n",
    "                    film_handle = get_movie_handle(str(tda.get('href')))\n",
    "\n",
    "            for tda in [td_list[j_RELEASE_DATE].a]:\n",
    "                found_date = None\n",
    "                if not tda is None:\n",
    "                    try:\n",
    "                        found_string = tda.string\n",
    "                    except:\n",
    "                        found_string = \"unknown\"\n",
    "                    \n",
    "                    if found_string.lower() != \"unknown\":\n",
    "                        try:\n",
    "                            found_date = dateparse(found_string).date()\n",
    "                        except:\n",
    "                            print(\"MINOR ISSUE: unable to dateparse this: {\" + repr(tda) + \"}\")\n",
    "                        \n",
    "                if found_date is None:\n",
    "                    print(\"MINOR_ISSUE: film {\" + film_handle + \"} is missing a release date in {\" + bgt_glob_url + \"} glob.\")\n",
    "                \n",
    "                bgt_release_date = found_date\n",
    "\n",
    "            for td in [td_list[j_PRODUCTION_BUDGET]]:\n",
    "                if td is None:\n",
    "                    bgt_productionBudget_dollars = -1\n",
    "                else:\n",
    "                    bgt_productionBudget_dollars = int(\"\".join([r for r in td.string if not r in TN_SALES_OMIT]))\n",
    "                    \n",
    "            for td in [td_list[j_DOMESTIC_GROSS]]:\n",
    "                if td is None:\n",
    "                    bgt_domUS_gross_dollars = -1\n",
    "                else:\n",
    "                    bgt_domUS_gross_dollars = int(\"\".join([r for r in td.string if not r in TN_SALES_OMIT]))\n",
    "                    \n",
    "            for td in [td_list[j_WORLDWIDE_GROSS]]:\n",
    "                if td is None:\n",
    "                    bgt_world_gross_dollars = -1\n",
    "                else:\n",
    "                    bgt_world_gross_dollars = int(\"\".join([r for r in td.string if not r in TN_SALES_OMIT]))\n",
    "\n",
    "                    \n",
    "            bgt_doss = dict()\n",
    "            bgt_doss['01_film_handle'] = film_handle\n",
    "            bgt_doss['bgt_release_date'] = bgt_release_date\n",
    "            bgt_doss['bgt_productionBudget_dollars'] = bgt_productionBudget_dollars\n",
    "            bgt_doss['bgt_domUS_gross_dollars'] = bgt_domUS_gross_dollars\n",
    "            bgt_doss['bgt_world_gross_dollars'] = bgt_world_gross_dollars\n",
    "                    \n",
    "            # Check whether a dossier already exists for this movieHandle.\n",
    "            # If a dossier does not already exist, create an empty dossier for it.\n",
    "            try:\n",
    "                old_doss = movieHandle_to_movieDoss[film_handle]\n",
    "            except:\n",
    "                movieHandle_to_movieDoss[film_handle] = dict()\n",
    "            # Assign values for top-level keys\n",
    "            # Top-level key-value pairs contain static (non-time-dependent) information about the film\n",
    "            for k in bgt_doss.keys():\n",
    "                # Check whether key k is already defined in the dossier\n",
    "                new_val = bgt_doss[k]\n",
    "                try:\n",
    "                    old_val = movieHandle_to_movieDoss[film_handle][k]\n",
    "                except:\n",
    "                    movieHandle_to_movieDoss[film_handle][k] = new_val\n",
    "        \n",
    "        bgt_rows_cumulative += num_data_rows \n",
    "        comm4(\"All {\" + str(num_data_rows)+ \"} data rows in the table were processed as expected.\")\n",
    "        comm4(\"\")\n",
    "\n",
    "        if num_data_rows < 100:\n",
    "            comm2(\"The last table has been harvested.\")\n",
    "            comm2(\"\")\n",
    "            quite_done = True\n",
    "            issues_found = False\n",
    "            break\n",
    "        \n",
    "        # This tells us the rank of the first movie in the next glob to be harvested\n",
    "        bgt_rank_nextup += 100\n",
    "        \n",
    "        if bgt_rank_nextup > bgt_rank_max:\n",
    "            comm2(\"ISSUE: The desired maximum number of rows {\" + str(bgt_rank_max)+ \"} has been reached.\")\n",
    "            comm2(\"\")\n",
    "            quite_done = True\n",
    "            break\n",
    "            \n",
    "\n",
    "    if issues_found:\n",
    "        comm4(\"ISSUES were encountered while processing file {\" + bgt_glob_path + \"}.\")\n",
    "        comm4(\"\")\n",
    "    else:\n",
    "        comm2(\"Data from file {\" + bgt_glob_path + \"} was processed without issues.\")\n",
    "        comm4(\"A total of {\" + str(bgt_rows_cumulative)+ \"} data rows were processed, so far.\")\n",
    "        comm4(\"\")\n",
    "    \n",
    "    comm4(\"bgt_rows_cumulative = \" + repr(bgt_rows_cumulative))\n",
    "    comm4(\"\")\n",
    "    print(\"DONE PERFORMING harvest of [movies sorted by production budget].\")\n",
    "    print()\n",
    "    \n",
    "harvest_tgy = True\n",
    "if not harvest_tgy:\n",
    "    print(\"SKIPPING harvest of top-grossing movies by year...\")\n",
    "    print()\n",
    "else:  \n",
    "    print(\"PERFORMING harvest of top-grossing movies by year...\")\n",
    "    print()\n",
    "\n",
    "    COMMENTARY_LEVEL = 3\n",
    "\n",
    "    tgy_desired_year_first = 1977\n",
    "    tgy_desired_year_last = 2020\n",
    "    tgy_desired_years = [i for i in range(tgy_desired_year_first,\n",
    "                                          (tgy_desired_year_last + 1))]\n",
    "\n",
    "    comm1(\"============================================\")\n",
    "    comm1(\"   HARVESTING DATA FROM [ANNUAL TABLES OF\")\n",
    "    comm1(\"   OF MOVIES RANKED BY DOMESTIC GROSS]\")\n",
    "    comm1(\"   for the following box office years:\")\n",
    "    comm1(\"   \" + repr(tgy_desired_years))\n",
    "    comm1(\"============================================\")\n",
    "    comm1(\"\")\n",
    "\n",
    "    for tgy_desired_year in tgy_desired_years:\n",
    "\n",
    "        quite_done = False\n",
    "        issues_found = True\n",
    "        while not quite_done:\n",
    "\n",
    "            comm4(\"=============================================================================================\")\n",
    "            comm4(\"\")\n",
    "\n",
    "            comm3(\"Importing table of movies ranked by [domestic gross during box office year \" + str(tgy_desired_year) + \"]...\")\n",
    "            comm4(\"\")\n",
    "\n",
    "            tgy_table_path = tnURL_topGross_byYear(tgy_desired_year, as_path=True)\n",
    "            tgy_table_url = tnURL_topGross_byYear(tgy_desired_year)\n",
    "\n",
    "            comm4(tgy_table_path)\n",
    "            comm4(\"\")\n",
    "            comm4(tgy_table_url)\n",
    "            comm4(\"\")\n",
    "\n",
    "            if not local_curated_file_exists(tgy_table_path, tgy_table_url):\n",
    "                print(\"Issue: Attempt to store webContent at URL {\" + \n",
    "                      tgy_table_url + \"} as local file {\" + \n",
    "                      tgy_table_path + \"} has failed.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "\n",
    "            comm4(\"Getting HTML content from local file {\" + tgy_table_path + \"} as soup...\")\n",
    "            comm4(\"\")\n",
    "            try:\n",
    "                with open(tgy_table_path, 'rb') as g:\n",
    "                    localContent = g.read()\n",
    "                    soup = BeautifulSoup(\n",
    "                        localContent, \"html.parser\")\n",
    "            except:\n",
    "                print(\"Issue: Attempt retrieve curated webContent from local file {\" + \n",
    "                      tgy_table_path + \"} has failed.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "\n",
    "            comm4(\"Identifying tables in soup...\")\n",
    "            comm4(\"\")\n",
    "\n",
    "            soup_tables = soup.find_all(\"table\")\n",
    "\n",
    "            num_soup_tables = len(soup_tables)\n",
    "            comm4(\"num_soup_tables = \" + repr(num_soup_tables))\n",
    "            comm4(\"\")\n",
    "\n",
    "            if num_soup_tables == 0:\n",
    "                print(\"ISSUE: No tables were identified in soup.\")\n",
    "                print(\"Did not obtain tabular data from URL {\" + tgy_table_url + \"}.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "\n",
    "            if num_soup_tables > 1:\n",
    "                comm4(\"A total of \" + str(num_soup_tables) + \" tables were identified in soup.\")\n",
    "                comm4(\"Only the first table will be examined.\")\n",
    "            table = soup_tables[0]\n",
    "\n",
    "            # Look for the header row, then extract headers from it, if found.\n",
    "            comm4(\"Now processing the HEADER ROW...\")\n",
    "            comm4(\"\")\n",
    "            contains_th = lambda tag: len(tag.find_all(\"th\")) > 0        \n",
    "\n",
    "            tr_list = [tr for tr in table.find_all(\"tr\", recursive=False) if contains_th(tr)]\n",
    "\n",
    "            num_header_rows = len(tr_list)\n",
    "            comm4(\"num_header_rows = \" + repr(num_header_rows))\n",
    "            comm4(\"\")\n",
    "            if num_header_rows == 0:\n",
    "                print(\"ISSUE: No header row was identified in the table.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "            if num_header_rows > 1:\n",
    "                comm4(\"A total of \" + str(num_header_rows) + \" header rows were identified in the table.\")\n",
    "                comm4(\"Only the first header row will be examined.\")\n",
    "                comm4(\"\")\n",
    "\n",
    "            original_headers = [\" \".join(th.strings) for th in tr_list[0].find_all(\"th\")]\n",
    "\n",
    "            table_num_columns = len(original_headers)\n",
    "            comm4(\"table_num_columns = \" + repr(table_num_columns))\n",
    "            comm4(\"\")\n",
    "            if table_num_columns == 0:\n",
    "                print(\"ISSUE: No column headers were found in the header row.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "\n",
    "            comm4(\"The following column headers were identified:\")\n",
    "            comm4(repr(original_headers))\n",
    "            comm4(\"\")\n",
    "                    \n",
    "            # correlate original headers with column indices\n",
    "            colHeader_to_j = dict(zip(original_headers, [j for j in range(table_num_columns)]))\n",
    "            j_YYYY_DOMUS_GROSS_RANK = colHeader_to_j['Rank']\n",
    "            j_MOVIE = colHeader_to_j['Movie']\n",
    "            j_RELEASE_DATE = colHeader_to_j['Release Date']\n",
    "            j_DISTRIBUTOR = colHeader_to_j['Distributor']\n",
    "            j_GENRE = colHeader_to_j['Genre']\n",
    "            j_YYYY_DOMUS_GROSS = colHeader_to_j[str(tgy_desired_year) + ' Gross']\n",
    "            j_YYYY_DOMUS_TICKETS = colHeader_to_j['Tickets Sold']\n",
    "\n",
    "            table_BOX_OFFICE_YEAR = original_headers[j_YYYY_DOMUS_GROSS][0:4]\n",
    "            comm4(\"table_BOX_OFFICE_YEAR = \" + table_BOX_OFFICE_YEAR)\n",
    "            comm4(\"\")\n",
    "            \n",
    "            # Make sure the box office year embedded in the column header is the \n",
    "            # same as the desired year\n",
    "            if table_BOX_OFFICE_YEAR != str(tgy_desired_year):\n",
    "                print(\"ISSUE: A column header mentions year {\" + table_BOX_OFFICE_YEAR +\n",
    "                      \"}, whereas {\" + str(tgy_desired_year) + \"} is the desired year.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "\n",
    "            comm4(\"Now processing the DATA ROWS...\")\n",
    "            comm4(\"\")\n",
    "\n",
    "            contains_a = lambda tag: len(tag.find_all(\"a\")) > 0\n",
    "            contains_td = lambda tag: len(tag.find_all(\"td\")) > 0        \n",
    "            tr_list = [tr for tr in table.find_all(\"tr\", recursive=False) if contains_a(tr) & contains_td(tr)]\n",
    "\n",
    "            num_data_rows = len(tr_list)\n",
    "            comm4(\"num_data_rows = \" + repr(num_data_rows))\n",
    "            comm4(\"\")\n",
    "            if num_data_rows == 0:\n",
    "                print(\"ISSUE: No data rows were identified in the table.\")\n",
    "                quite_done = True\n",
    "                break\n",
    "\n",
    "            for i, tr in enumerate(tr_list):\n",
    "                td_list = tr.find_all(\"td\")\n",
    "\n",
    "                num_td = len(td_list)\n",
    "                if num_td < table_num_columns:\n",
    "                    print(\"ISSUE: Only \"+ str(num_td) + \" data elements were identified \" +\n",
    "                          \"in the data row whose index is {\" + str(i) + \"} .\")\n",
    "                    print(\"Each data row in the table was expected to have {\" + str(table_num_columns) + \"} columns .\")\n",
    "                    quite_done = True\n",
    "                    break\n",
    "\n",
    "                tgy_YYYY = table_BOX_OFFICE_YEAR\n",
    "                \n",
    "                for td in [td_list[j_YYYY_DOMUS_GROSS_RANK]]:\n",
    "                    if td is None:\n",
    "                        tgy_domUSsales_dollars_rank_boxOfficeYear = None\n",
    "                    else:\n",
    "                        tgy_domUSsales_dollars_rank_boxOfficeYear = int(td.string)\n",
    "\n",
    "                for tda in [td_list[j_MOVIE].a]:\n",
    "                    if tda is None:\n",
    "                        film_handle = None\n",
    "                        tgy_film_href = None\n",
    "                        tgy_film_title = None\n",
    "                        tgy_film_url = None\n",
    "                    else:\n",
    "                        film_handle = get_movie_handle(str(tda.get('href')))\n",
    "                        tgy_film_href = str(tda.get('href'))\n",
    "                        tgy_film_title = tda.string\n",
    "                        tgy_film_url = TN_MAIN_URL + str(tda.get('href'))\n",
    "\n",
    "                for tda in [td_list[j_RELEASE_DATE].a]:\n",
    "                    \n",
    "                    found_date = None\n",
    "                    if not tda is None:\n",
    "                        try:\n",
    "                            found_string = tda.string\n",
    "                        except:\n",
    "                            found_string = \"unknown\"\n",
    "\n",
    "                        if found_string.lower() != \"unknown\":\n",
    "                            try:\n",
    "                                found_date = dateparse(found_string).date()\n",
    "                            except:\n",
    "                                print(\"MINOR_ISSUE: unable to dateparse this: {\" + repr(tda) + \"}.\")\n",
    "\n",
    "                    if found_date is None:\n",
    "                        comm2(\"MINOR_ISSUE: film {\" + film_handle + \n",
    "                              \"} is missing a release date in the {\" + \n",
    "                              tgy_YYYY + \"_topGross} table.\")\n",
    "                    \n",
    "                    tgy_release_date = found_date\n",
    "                    \n",
    "                    if tda is None:\n",
    "                        tgy_release_href = None\n",
    "                        tgy_release_url = None\n",
    "                    else:\n",
    "                        tgy_release_href = str(tda.get('href'))\n",
    "                        tgy_release_url = TN_MAIN_URL + str(tda.get('href'))\n",
    "\n",
    "                for tda in [td_list[j_DISTRIBUTOR].a]:\n",
    "                    if tda is None:\n",
    "                        tgy_distrib_href = None\n",
    "                        tgy_distrib_handle = None\n",
    "                        tgy_distrib_name = None\n",
    "                        tgy_distrib_url = None\n",
    "                    else:\n",
    "                        tgy_distrib_href = str(tda.get('href'))\n",
    "                        tgy_distrib_handle = get_distrib_handle(str(tda.get('href')))\n",
    "                        tgy_distrib_name = tda.string\n",
    "                        tgy_distrib_url = TN_MAIN_URL + str(tda.get('href'))\n",
    "\n",
    "                for tda in [td_list[j_GENRE].a]:\n",
    "                    if tda is None:\n",
    "                        tgy_genre_href = None\n",
    "                        tgy_genre_handle = TN_GENRE_HANDLES[0]\n",
    "                        tgy_genre_abbr = TN_GENRE_ABBRS[0]\n",
    "                        tgy_genre_name = None\n",
    "                        tgy_genre_url = None\n",
    "                    else:\n",
    "                        tgy_genre_href = str(tda.get('href'))\n",
    "                        tgy_genre_handle = get_genre_handle(str(tda.get('href')))\n",
    "                        tgy_genre_abbr = gHandle_to_gAbbr[get_genre_handle(str(tda.get('href')))]\n",
    "                        tgy_genre_name = tda.string\n",
    "                        tgy_genre_url = TN_MAIN_URL + str(tda.get('href'))\n",
    "                \n",
    "                for td in [td_list[j_YYYY_DOMUS_GROSS]]:\n",
    "                    if td is None:\n",
    "                        tgy_domUSsales_dollars_boxOfficeYear = -1\n",
    "                    else:\n",
    "                        tgy_domUSsales_dollars_boxOfficeYear = int(\"\".join([r for r in td.string if not r in TN_SALES_OMIT]))\n",
    "                \n",
    "                for td in [td_list[j_YYYY_DOMUS_TICKETS]]:\n",
    "                    if td is None:\n",
    "                        tgy_domUSsales_tickets_boxOfficeYear = -1\n",
    "                    else:\n",
    "                        tgy_domUSsales_tickets_boxOfficeYear = int(\"\".join([r for r in td.string if not r in TN_SEATS_OMIT]))\n",
    "\n",
    "                if COMMENTARY_LEVEL >= 4:\n",
    "                    print(\"01_film_handle = \" + repr(film_handle))\n",
    "                    print(\"tgy_film_title = \" + repr(tgy_film_title))\n",
    "                    print(\"tgy_film_url = \" + repr(tgy_film_url))\n",
    "                    print(\"tgy_release_date = \" + repr(tgy_release_date))\n",
    "                    print(\"tgy_release_url = \" + repr(tgy_release_url))\n",
    "                    print(\"tgy_distrib_handle = \" + repr(tgy_distrib_handle))\n",
    "                    print(\"tgy_distrib_name = \" + repr(tgy_distrib_name))\n",
    "                    print(\"tgy_distrib_url = \" + repr(tgy_distrib_url))\n",
    "                    print(\"tgy_genre_handle = \" + repr(tgy_genre_handle))\n",
    "                    print(\"tgy_genre_abbr = \" + repr(tgy_genre_abbr))\n",
    "                    print(\"tgy_genre_name = \" + repr(tgy_genre_name))\n",
    "                    print(\"tgy_genre_url = \" + repr(tgy_genre_url))\n",
    "                    print(\"tgy_YYYY = \" + repr(tgy_YYYY))\n",
    "                    print(\"tgy_domUSsales_dollars_rank_\" + tgy_YYYY + \" = \" + repr(tgy_domUSsales_dollars_rank_boxOfficeYear))\n",
    "                    print(\"tgy_domUSsales_dollars_\" + tgy_YYYY + \" = \" + repr(tgy_domUSsales_dollars_boxOfficeYear))\n",
    "                    print(\"tgy_domUSsales_tickets_\" + tgy_YYYY + \" = \" + repr(tgy_domUSsales_tickets_boxOfficeYear))\n",
    "                    print(\"\")\n",
    "                    print(\"=========================\")\n",
    "                    print(\"\")\n",
    "\n",
    "                tgy_doss = dict()\n",
    "                tgy_doss['01_film_handle'] = film_handle\n",
    "                tgy_doss['03_genre_abbr'] = tgy_genre_abbr\n",
    "                # tgy_doss['tgy_film_title'] = tgy_film_title\n",
    "                # tgy_doss['tgy_film_url'] = tgy_film_url\n",
    "                tgy_doss['04_distrib_handle'] = tgy_distrib_handle\n",
    "                tgy_doss['tgy_boxOfficeYears'] = tgy_desired_year\n",
    "                tgy_doss['tgy_release_dates'] = tgy_release_date\n",
    "                # tgy_doss['tgy_domUSsales_dollars_rank_' + tgy_YYYY] = tgy_domUSsales_dollars_rank_boxOfficeYear\n",
    "                tgy_doss['tgy_domUSsales_dollars_' + tgy_YYYY] = tgy_domUSsales_dollars_boxOfficeYear\n",
    "                tgy_doss['tgy_domUSsales_tickets_' + tgy_YYYY] = tgy_domUSsales_tickets_boxOfficeYear\n",
    "\n",
    "                # Check whether a dossier already exists for this movieHandle.\n",
    "                # If a dossier does not already exist, create an empty dossier for it.\n",
    "                try:\n",
    "                    old_doss = movieHandle_to_movieDoss[film_handle]\n",
    "                except:\n",
    "                    movieHandle_to_movieDoss[film_handle] = dict()\n",
    "                # Assign values for top-level keys\n",
    "                # Top-level key-value pairs contain static (non-time-dependent) information about the film\n",
    "                for k in tgy_doss.keys():\n",
    "                    new_val = tgy_doss[k]\n",
    "                    if k in [\"tgy_boxOfficeYears\", \"tgy_release_dates\"]:\n",
    "                        # Check whether this k-list is already present for this movieHandle\n",
    "                        # If the k-list does not already exist, create it as an empty list.\n",
    "                        try:\n",
    "                            old_val = movieHandle_to_movieDoss[film_handle][k]\n",
    "                        except:\n",
    "                            movieHandle_to_movieDoss[film_handle][k] = list()\n",
    "                        # Append the new value to the k-list\n",
    "                        movieHandle_to_movieDoss[film_handle][k].append(new_val)\n",
    "                        \n",
    "                        if k in [\"tgy_release_dates\"]:\n",
    "                            # force update of \"tgy_release_date\", because a new date\n",
    "                            # entry may exist for the current movieHandle\n",
    "                            dates_raw = movieHandle_to_movieDoss[film_handle][k]\n",
    "                            dates_valid = [d for d in dates_raw if isinstance(d, datetime.date)]\n",
    "                            if len(dates_valid) == 0:\n",
    "                                date_earliest = None\n",
    "                            else:\n",
    "                                date_earliest = min(dates_valid)\n",
    "                                if not isinstance(date_earliest, datetime.date):\n",
    "                                    print(\"The earliest date in dates_valid is not a date...\" + repr(dates_valid))\n",
    "                                    print(\"dates_valid = \" + repr(dates_valid))\n",
    "                                    print(\"date_earliest = \" + repr(date_earliest))\n",
    "                                    print()\n",
    "                            movieHandle_to_movieDoss[film_handle][\"tgy_release_date\"] = date_earliest\n",
    "                                    \n",
    "                    else:\n",
    "                        # Check whether key k is already defined in the dossier\n",
    "                        try:\n",
    "                            old_val = movieHandle_to_movieDoss[film_handle][k]\n",
    "                        except:\n",
    "                            movieHandle_to_movieDoss[film_handle][k] = new_val\n",
    "\n",
    "                if not tgy_distrib_handle is None:\n",
    "                    distrib_doss = dict()\n",
    "                    distrib_doss['distrib_href'] = tgy_distrib_href\n",
    "                    distrib_doss['distrib_handle'] = tgy_distrib_handle\n",
    "                    distrib_doss['distrib_name'] = tgy_distrib_name\n",
    "                    distrib_doss['distrib_url'] = tgy_distrib_url\n",
    "\n",
    "                    # Check whether a dossier already exists for this distribHandle.\n",
    "                    # If a dossier does not already exist, create an empty dossier for it.\n",
    "                    try:\n",
    "                        old_doss = distribHandle_to_distribDoss[tgy_distrib_handle]\n",
    "                    except:\n",
    "                        distribHandle_to_distribDoss[tgy_distrib_handle] = dict()\n",
    "                    # Assign values for top-level keys\n",
    "                    # Top-level key-value pairs contain static (non-time-dependent) information about the film\n",
    "                    for k in distrib_doss.keys():\n",
    "                        # Check whether key k is already defined in the dossier\n",
    "                        new_val = distrib_doss[k]\n",
    "                        try:\n",
    "                            old_val = distribHandle_to_distribDoss[tgy_distrib_handle][k]\n",
    "                        except:\n",
    "                            distribHandle_to_distribDoss[tgy_distrib_handle][k] = new_val\n",
    "\n",
    "                if not tgy_genre_handle is None:\n",
    "                    genre_doss = dict()\n",
    "                    genre_doss['genre_href'] = tgy_genre_href\n",
    "                    genre_doss['genre_handle'] = tgy_genre_handle\n",
    "                    genre_doss['genre_abbr'] = tgy_genre_abbr\n",
    "                    genre_doss['genre_name'] = tgy_genre_name\n",
    "                    genre_doss['genre_url'] = tgy_genre_url\n",
    "\n",
    "                    # Check whether a dossier already exists for this genreHandle.\n",
    "                    # If a dossier does not already exist, create an empty dossier for it.\n",
    "                    try:\n",
    "                        old_doss = genreHandle_to_genreDoss[tgy_genre_handle]\n",
    "                    except:\n",
    "                        genreHandle_to_genreDoss[tgy_genre_handle] = dict()\n",
    "                    # Assign values for top-level keys\n",
    "                    # Top-level key-value pairs contain static (non-time-dependent) information about the film\n",
    "                    for k in genre_doss.keys():\n",
    "                        # Check whether key k is already defined in the dossier\n",
    "                        new_val = genre_doss[k]\n",
    "                        try:\n",
    "                            old_val = genreHandle_to_genreDoss[tgy_genre_handle][k]\n",
    "                        except:\n",
    "                            genreHandle_to_genreDoss[tgy_genre_handle][k] = new_val\n",
    "\n",
    "            tgy_rows_cumulative += num_data_rows \n",
    "            comm4(\"All {\" + str(num_data_rows)+ \"} data rows in the table were processed as expected.\")\n",
    "            comm4(\"\")\n",
    "\n",
    "            quite_done = True\n",
    "            issues_found = False\n",
    "\n",
    "        if issues_found:\n",
    "            print(\"ISSUES were encountered while processing URL {\" + tgy_table_url + \"}.\")\n",
    "            comm2(\"A total of {\" + str(tgy_rows_cumulative)+ \"} data rows were processed, so far.\")\n",
    "            comm2(\"\")\n",
    "        else:\n",
    "            comm2(\"Data from URL {\" + tgy_table_url + \"} was processed without issues.\")\n",
    "            comm4(\"A total of {\" + str(tgy_rows_cumulative)+ \"} data rows were processed, so far.\")\n",
    "            comm4(\"\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#   IN THIS SECTION,\n",
    "#       POST-PROCESSING OF THE DATA HARVESTED ABOVE IS PERFORMED.\n",
    "#\n",
    "#       EACH MODE OF POST-HARVEST PROCESSING\n",
    "#       MAY OPTIONALLY BE PERFORMED AT THE DISCRETION OF THE USER\n",
    "#       BY SETTING \"identify_????\" FLAGS AND/OR\n",
    "#                  \"mend_????\" FLAGS\n",
    "#       TO True or False, ACCORDINGLY\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "identify_unique_movieHandles = True\n",
    "if not identify_unique_movieHandles:\n",
    "    print(\"SKIPPING identification of unique movie handles...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"IDENTIFYING unique movie handles...\")\n",
    "    print()\n",
    "    \n",
    "    # Make a list of all unique movie handles that were encountered \n",
    "    # during the harvesting of data\n",
    "    movieHandles_all = sorted([k for k in movieHandle_to_movieDoss.keys()], \n",
    "                              key=lambda s: s.lower())\n",
    "    num_movieHandles = len(movieHandles_all)\n",
    "    print(\"num_movieHandles = \" + str(num_movieHandles))\n",
    "    print()\n",
    "    num_display = 50\n",
    "    print(\"MOVIE HANDLES:  FIRST \" + str(num_display) +\n",
    "          \" AND LAST \" + str(num_display) + \"...\")\n",
    "    i_all = list(range(num_movieHandles))\n",
    "    i_show = i_all[0:num_display] + i_all[-num_display:]\n",
    "    for i in i_show:\n",
    "        print(\"movieHandles_all[\" + str(i) + \"] = \" + movieHandles_all[i])\n",
    "    print()\n",
    "            \n",
    "identify_unique_genreHandles = True\n",
    "if not identify_unique_genreHandles:\n",
    "    print(\"SKIPPING identification of unique genre handles...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"IDENTIFYING unique genre handles...\")\n",
    "    print()\n",
    "    \n",
    "    # Make a list of all unique genre handles that were encountered \n",
    "    # during the harvesting of data\n",
    "    genreHandles_all = sorted([k for k in genreHandle_to_genreDoss.keys()], \n",
    "                              key=lambda s: s.lower())\n",
    "    num_genreHandles = len(genreHandles_all)\n",
    "    print(\"num_genreHandles = \" + str(num_genreHandles))\n",
    "    print()\n",
    "    num_display = 50\n",
    "    if num_genreHandles < (2 * num_display):\n",
    "        print(\"GENRE HANDLES:  ALL \" + str(num_genreHandles) + \" HANDLES...\")\n",
    "        i_show = list(range(num_genreHandles))\n",
    "    else:\n",
    "        print(\"GENRE HANDLES:  FIRST \" + str(num_display) +\n",
    "              \" AND LAST \" + str(num_display) + \"...\")\n",
    "        i_all = list(range(num_genreHandles))\n",
    "        i_show = i_all[0:num_display] + i_all[-num_display:]\n",
    "    for i in i_show:\n",
    "        print(\"genreHandles_all[\" + str(i) + \"] = \" + genreHandles_all[i])\n",
    "    print()\n",
    "\n",
    "identify_unique_distribHandles = True\n",
    "if not identify_unique_distribHandles:\n",
    "    print(\"SKIPPING identification of unique distributor handles...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"IDENTIFYING unique distributor handles...\")\n",
    "    print()\n",
    "\n",
    "    # Make a list of all unique distributor handles that were encountered \n",
    "    # during the harvesting of data\n",
    "    distribHandles_all = sorted([k for k in distribHandle_to_distribDoss.keys()], \n",
    "                                key=lambda s: s.lower())\n",
    "    num_distribHandles = len(distribHandles_all)\n",
    "    print(\"num_distribHandles = \" + str(num_distribHandles))\n",
    "    print()\n",
    "    num_display = 50\n",
    "    if num_distribHandles < (2 * num_display):\n",
    "        print(\"DISTRIBUTOR HANDLES:  ALL \" + str(num_distribHandles) + \" HANDLES...\")\n",
    "        i_show = list(range(num_distribHandles))\n",
    "    else:\n",
    "        print(\"DISTRIBUTOR HANDLES:  FIRST \" + str(num_display) +\n",
    "              \" AND LAST \" + str(num_display) + \"...\")\n",
    "        i_all = list(range(num_distribHandles))\n",
    "        i_show = i_all[0:num_display] + i_all[-num_display:]\n",
    "    for i in i_show:\n",
    "        print(\"distribHandles_all[\" + str(i) + \"] = \" + distribHandles_all[i])\n",
    "    print()\n",
    "    \n",
    "\n",
    "mend_genre_abbrs = True\n",
    "if not mend_genre_abbrs:\n",
    "    print(\"SKIPPING mending of genre abbreviations...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"PERFORMING mending of genre abbreviations...\")\n",
    "    print()\n",
    "\n",
    "    # Not all movies that were encountered during the harvesting of data\n",
    "    # had genre information available to be stored in the movie's dossier.\n",
    "\n",
    "    # Force those movies that are MISSING the genre information to have\n",
    "    # genre abbreviation TN_GENRE_ABBRS[0], which is regarded as \"undefined genre\"\n",
    "    \n",
    "    for mh in movieHandles_all:\n",
    "        g_abbr = None\n",
    "        try:\n",
    "            g_abbr = movieHandle_to_movieDoss[mh][\"03_genre_abbr\"]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if not g_abbr in TN_GENRE_ABBRS:\n",
    "            movieHandle_to_movieDoss[mh][\"03_genre_abbr\"] = TN_GENRE_ABBRS[0]\n",
    "\n",
    "            \n",
    "mend_release_dates = True\n",
    "if not mend_release_dates:\n",
    "    print(\"SKIPPING mending of release dates...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"PERFORMING mending of release dates...\")\n",
    "    print()\n",
    "\n",
    "    # Not all movies that were encountered during the harvesting of data\n",
    "    # had \"release date\" information available to be stored in the movie's dossier.\n",
    "\n",
    "    # To complicate things further, the \"release date\" information harvested from\n",
    "    # source A (if release date information was in fact obtained from source A) \n",
    "    # MAY differ from the \"release date\" information harvested from source B (if\n",
    "    # release date information was in fact obtained from source B).\n",
    "\n",
    "    # In the event that there appear to be two different values of \"release date\"\n",
    "    # for the same movie, the EARLIER of the two values will be regarded as correct.\n",
    "    \n",
    "    for mh in movieHandles_all:\n",
    "        date_A = \"--absent--\"\n",
    "        try:\n",
    "            date_A = movieHandle_to_movieDoss[mh][\"bgt_release_date\"]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        date_B = \"--absent--\"\n",
    "        try:\n",
    "            date_B = movieHandle_to_movieDoss[mh][\"tgy_release_date\"]\n",
    "        except:\n",
    "            pass\n",
    "           \n",
    "        if not isinstance(date_A, datetime.date):\n",
    "            if not isinstance(date_B, datetime.date):\n",
    "                date_release = None\n",
    "            else:\n",
    "                date_release = date_B\n",
    "        else:\n",
    "            if not isinstance(date_B, datetime.date):\n",
    "                date_release = date_A\n",
    "            else:\n",
    "                date_release = min(date_A, date_B)\n",
    "        \n",
    "        movieHandle_to_movieDoss[mh][\"02_film_release_date\"] = date_release\n",
    "        year_release = date_to_boxOfficeYear(date_release)\n",
    "        if isinstance(year_release, int):\n",
    "            pass\n",
    "        if not isinstance(year_release, int):\n",
    "            if not year_release is None:\n",
    "                print(\"Error: date_to_boxOfficeYear(\" + repr(date_release)+ \") = \" + repr(year_release))\n",
    "        movieHandle_to_movieDoss[mh][\"02_film_release_year\"] = year_release\n",
    "            \n",
    "    print(\"all movieHandles whose 'release_date' is a non-date, AFTER mending of release dates:\")\n",
    "    movieHandles_undated = [mh for mh in movieHandles_all if not\n",
    "                            isinstance(movieHandle_to_movieDoss[mh]['02_film_release_date'], datetime.date)]   \n",
    "    for mh in movieHandles_undated:\n",
    "        mh_date_keys = [k for k in movieHandle_to_movieDoss[mh].keys() if \"date\" in k]\n",
    "        mh_date_values = [movieHandle_to_movieDoss[mh][dk] for dk in mh_date_keys]\n",
    "        mh_date = dict(zip(mh_date_keys, mh_date_values))\n",
    "        print(\"     \" + repr(mh) + \": \" + repr(mh_date) )\n",
    "    print()\n",
    "\n",
    "    \n",
    "display_selected_movie_dossiers = True\n",
    "if not display_selected_movie_dossiers:\n",
    "    print(\"SKIPPING display of selected movie dossiers...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"DISPLAYING selected movie dossiers...\")\n",
    "    print()    \n",
    "    \n",
    "    num_display = 20\n",
    "    print(\"MOVIE DOSSIERS:  FIRST \" + str(num_display) +\n",
    "          \" AND LAST \" + str(num_display) + \"...\")\n",
    "    i_all = list(range(num_movieHandles))\n",
    "    i_show = i_all[0:num_display] + i_all[-num_display:]\n",
    "    for i in i_show:\n",
    "        print(\"i = \" + str(i) + \":\")\n",
    "        mh_doss = movieHandle_to_movieDoss[movieHandles_all[i]]\n",
    "        mh_keys = sorted(mh_doss.keys(), key=lambda s: s.lower()) \n",
    "        for k in mh_keys:\n",
    "            print(repr(k) + \": \" + repr(mh_doss[k]))\n",
    "        print()\n",
    "\n",
    "        \n",
    "\n",
    "# ==============================================================================\n",
    "#   IN THIS SECTION,\n",
    "#       SOME OF THE INFORMATION STORED IN movieHandle_to_movieDoss\n",
    "#       IS PORTED INTO A NEW DICTIONARY CALLED \"eventHandle_to_eventDoss\"\n",
    "#\n",
    "#       TO BE PORTED INTO THE EVENTS DICTIONARY, A PARTICULAR MOVIE\n",
    "#       MUST ALREADY CONTAIN SPECIFIC ITEMS OF INFORMATION IN ITS MOVIE DOSSIER.\n",
    "#\n",
    "#       EACH MOVIE THAT APPEARS IN THE EVENTS DICTIONARY HAS AT LEAST ONE\n",
    "#       \"EVENT\" ASSOCIATED WITH IT.\n",
    "#       \n",
    "#       THE COMBINATION OF:\n",
    "#           [ONE BOX-OFFICE SALES YEAR] + [ONE GENRE] + [ONE MOVIE FROM WITHIN THAT GENRE]\n",
    "#       COMPRISE A UNIQUE \"EVENT HANDLE\".\n",
    "#       \n",
    "#       FOR EXAMPLE, THE 2009 ACTION MOVIE \"AVATAR\" HAD DOMESTIC US BOX OFFICE\n",
    "#       SALES DURING THE BOX OFFICE YEARS 2009 AND 2010.  THE INFORMATION FOR\n",
    "#       THE MOVIE AVATAR IS THEREFORE STORED IN THE EVENTS DICTIONARY\n",
    "#       UNDER THESE TWO EVENT HANDLES.\n",
    "#            EVENT HANDLE 1 = \"2009/ACTION/AVATAR\"\n",
    "#            EVENT HANDLE 2 = \"2010/ACTION/AVATAR\"\n",
    "#       \n",
    "#       ORGANIZATION OF THE MOVIE SALES FIGURES IN THIS FASHION FACILITATES\n",
    "#       ANALYSIS USING THE PANDAS \"GROUPBY\" FUNCTION.  \n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "movieHandles_in_eventDoss = []\n",
    "\n",
    "create_eventHandle_to_eventDoss = True\n",
    "if not create_eventHandle_to_eventDoss:\n",
    "    print(\"SKIPPING creation of eventHandle_to_eventDoss...\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"PERFORMING creation of eventHandle_to_eventDoss...\")\n",
    "    print()\n",
    "    \n",
    "    eventHandle_to_eventDoss = dict()\n",
    "\n",
    "    for mh in movieHandles_all:\n",
    "        mh_BOYs = None\n",
    "        try:\n",
    "            mh_BOYs = movieHandle_to_movieDoss[mh]['tgy_boxOfficeYears']\n",
    "        except:\n",
    "            print(\"didn't find movieHandle_to_movieDoss[\" + repr(mh) + \"]['tgy_boxOfficeYears']\")\n",
    "            pass\n",
    "        if isinstance(mh_BOYs, list):\n",
    "            mh_relDate = None\n",
    "            try:\n",
    "                mh_relDate = movieHandle_to_movieDoss[mh]['02_film_release_date']\n",
    "            except:\n",
    "                print(\"didn't find movieHandle_to_movieDoss[\" + repr(mh) + \"]['02_film_release_date']\")\n",
    "                pass\n",
    "            if isinstance(mh_relDate, datetime.date):\n",
    "                mh_pb = None\n",
    "                try:\n",
    "                    mh_pb = movieHandle_to_movieDoss[mh]['bgt_productionBudget_dollars']\n",
    "                except:\n",
    "                    print(\"didn't find movieHandle_to_movieDoss[\" + repr(mh) + \"]['bgt_productionBudget_dollars']\")\n",
    "                    pass\n",
    "                if isinstance(mh_pb, int):\n",
    "                    mh_domUS_gross = None\n",
    "                    try:\n",
    "                        mh_domUS_gross = movieHandle_to_movieDoss[mh]['bgt_domUS_gross_dollars']\n",
    "                    except:\n",
    "                        print(\"didn't find movieHandle_to_movieDoss[\" + repr(mh) + \"]['bgt_domUS_gross_dollars']\")\n",
    "                        pass  \n",
    "                    if isinstance(mh_domUS_gross, int):\n",
    "                        mh_world_gross = None\n",
    "                        try:\n",
    "                            mh_world_gross = movieHandle_to_movieDoss[mh]['bgt_world_gross_dollars']\n",
    "                        except:\n",
    "                            print(\"didn't find movieHandle_to_movieDoss[\" + repr(mh) + \"]['bgt_world_gross_dollars']\")\n",
    "                            pass  \n",
    "                        if isinstance(mh_world_gross, int):\n",
    "                            for iYear in mh_BOYs:\n",
    "                                event_iYear = iYear\n",
    "                                event_YYYY = str(event_iYear)\n",
    "                                event_genre_abbr = movieHandle_to_movieDoss[mh][\"03_genre_abbr\"]\n",
    "                                event_movie_handle = mh\n",
    "\n",
    "                                event_handle = event_YYYY + \"/\" + event_genre_abbr + \"/\" + event_movie_handle\n",
    "                                event_genreYear_handle = event_genre_abbr + \"/\" + event_YYYY\n",
    "\n",
    "                                mh_sales = None\n",
    "                                try:\n",
    "                                    mh_sales = movieHandle_to_movieDoss[mh]['tgy_domUSsales_dollars_' + event_YYYY]\n",
    "                                except:\n",
    "                                    pass  \n",
    "                                if isinstance(mh_sales, int):\n",
    "                                    mh_tickets = None\n",
    "                                    try:\n",
    "                                        mh_tickets = movieHandle_to_movieDoss[mh]['tgy_domUSsales_tickets_' + event_YYYY]\n",
    "                                    except:\n",
    "                                        pass  \n",
    "                                    if isinstance(mh_tickets, int):\n",
    "                                        pb_year = movieHandle_to_movieDoss[mh]['02_film_release_year']\n",
    "                                        pb_raw = movieHandle_to_movieDoss[mh]['bgt_productionBudget_dollars']\n",
    "                                        pb_mult = inflation_multiplier(from_year=pb_year, into_year=2020)\n",
    "                                        pb_adj = pb_raw * pb_mult\n",
    "\n",
    "                                        domUS_raw = movieHandle_to_movieDoss[mh]['tgy_domUSsales_dollars_' + event_YYYY]\n",
    "                                        domUS_mult = inflation_multiplier(from_year=event_iYear, into_year=2020)\n",
    "                                        domUS_adj = domUS_raw * domUS_mult\n",
    "\n",
    "                                        event_doss = dict()\n",
    "                                        event_doss[\"event_handle\"] = event_handle\n",
    "                                        event_doss[\"genreYear_handle\"] = event_genreYear_handle\n",
    "                                        event_doss['boxOfficeYear'] = event_iYear\n",
    "                                        event_doss[\"genre_abbr\"] = event_genre_abbr\n",
    "                                        event_doss[\"movie_handle\"] = event_movie_handle\n",
    "                                        event_doss[\"release_date\"] = movieHandle_to_movieDoss[mh]['02_film_release_date']\n",
    "                                        event_doss[\"productionBudget_year\"] = pb_year\n",
    "                                        event_doss[\"productionBudget_raw\"] = pb_raw\n",
    "                                        event_doss[\"productionBudget_mult\"] = pb_mult\n",
    "                                        event_doss[\"productionBudget_adj\"] = pb_adj\n",
    "                                        event_doss[\"total_world_gross\"] = movieHandle_to_movieDoss[mh]['bgt_world_gross_dollars']\n",
    "                                        event_doss[\"total_domUS_gross\"] = movieHandle_to_movieDoss[mh]['bgt_domUS_gross_dollars']\n",
    "                                        event_doss[\"boxOfficeYear_domUS_raw\"] = domUS_raw\n",
    "                                        event_doss[\"boxOfficeYear_domUS_mult\"] = domUS_mult\n",
    "                                        event_doss[\"boxOfficeYear_domUS_adj\"] = domUS_adj\n",
    "                                        event_doss[\"boxOfficeYear_domUS_tickets\"] = movieHandle_to_movieDoss[mh]['tgy_domUSsales_tickets_' + event_YYYY]\n",
    "                                        eventHandle_to_eventDoss[event_handle] = event_doss\n",
    "                                        \n",
    "                            movieHandles_in_eventDoss.append(mh)\n",
    "    print()\n",
    "    \n",
    "    num_movieHandles_in_eventDoss = len(movieHandles_in_eventDoss)\n",
    "    print(\"BEFORE ELMINATION OF DUPLICATES:\")\n",
    "    print(\"num_movieHandles_in_eventDoss = \" + str(num_movieHandles_in_eventDoss))\n",
    "    print()\n",
    "    \n",
    "    movieHandles_in_eventDoss = sorted(list(set(movieHandles_in_eventDoss)))\n",
    "    num_movieHandles_in_eventDoss = len(movieHandles_in_eventDoss)\n",
    "    print(\"AFTER ELMINATION OF DUPLICATES:\")\n",
    "    print(\"num_movieHandles_in_eventDoss = \" + str(num_movieHandles_in_eventDoss))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    eventHandles_all = sorted([k for k in eventHandle_to_eventDoss.keys()], \n",
    "                              key=lambda s: s.lower())\n",
    "    num_eventHandles = len(eventHandles_all)\n",
    "    print(\"num_eventHandles = \" + str(num_eventHandles))\n",
    "    print()\n",
    "    \n",
    "    # make the event handles in the events dictionary appear in increasing order by eventHandle\n",
    "    eventHandle_to_eventDoss_RAW = eventHandle_to_eventDoss\n",
    "    eventHandle_to_eventDoss = dict()\n",
    "    for k in eventHandles_all:\n",
    "        eventHandle_to_eventDoss[k] = eventHandle_to_eventDoss_RAW[k]\n",
    "    eventHandle_to_eventDoss_RAW = None\n",
    "    \n",
    "    num_display = 50\n",
    "    print(\"EVENT HANDLES:  FIRST \" + str(num_display) +\n",
    "          \" AND LAST \" + str(num_display) + \"...\")\n",
    "    i_all = list(range(num_eventHandles))\n",
    "    i_show = i_all[0:num_display] + i_all[-num_display:]\n",
    "    for i in i_show:\n",
    "        print(\"eventHandles_all[\" + str(i) + \"] = \" + eventHandles_all[i])\n",
    "    print()\n",
    "\n",
    "    num_display = 20\n",
    "    print(\"EVENT DOSSIERS:  FIRST \" + str(num_display) +\n",
    "          \" AND LAST \" + str(num_display) + \"...\")\n",
    "    i_all = list(range(num_eventHandles))\n",
    "    i_show = i_all[0:num_display] + i_all[-num_display:]\n",
    "    for i in i_show:\n",
    "        print(\"i = \" + str(i) + \":\")\n",
    "        eh_doss = eventHandle_to_eventDoss[eventHandles_all[i]]\n",
    "        eh_keys = eh_doss.keys()\n",
    "        for k in eh_keys:\n",
    "            print(repr(k) + \": \" + repr(eh_doss[k]))\n",
    "        print()\n",
    "\n",
    "        \n",
    "# Make a sound, to let the user know it's time to move on to the next cell\n",
    "make_beeps()\n",
    "\n",
    "# That should do it.  Thanks for reading my code.  -- MLC\n",
    "print(\"Get thee to the next cell.\")\n",
    "\n",
    "do_extra_stuff = False\n",
    "if do_extra_stuff:\n",
    "    # This is extra stuff\n",
    "    # so please don't knock me for lack of commentary\n",
    "\n",
    "    further_review_data = False\n",
    "    if not further_review_data:\n",
    "        print(\"SKIPPING further review of data...\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"PERFORMING further review of data...\")\n",
    "        print()\n",
    "\n",
    "        print(\"bgt_rows_cumulative = \" + str(bgt_rows_cumulative))\n",
    "        print()\n",
    "\n",
    "        print(\"tgy_rows_cumulative = \" + str(tgy_rows_cumulative))\n",
    "        print()\n",
    "\n",
    "        movieHandles_length = [len(h) for h in movieHandles_all]\n",
    "        movieHandles_length_min = min(movieHandles_length)\n",
    "        movieHandles_length_max = max(movieHandles_length)\n",
    "        movieHandles_shortest = [h for h in movieHandles_all if len(h) == movieHandles_length_min]\n",
    "        movieHandles_longest = [h for h in movieHandles_all if len(h) == movieHandles_length_max]\n",
    "        print(\"movieHandles_length_min = \" + str(movieHandles_length_min))\n",
    "        print(\"movieHandles_length_max = \" + str(movieHandles_length_max))\n",
    "        print(\"movieHandles_shortest = \" + repr(movieHandles_shortest))\n",
    "        print(\"movieHandles_longest = \" + repr(movieHandles_longest))\n",
    "        print()\n",
    "\n",
    "        try:\n",
    "            movieHandles_with_releaseDate = [h for h in movieHandles_all if not movieHandle_to_movieDoss[h]['02_film_release_date'] is None]\n",
    "            num_movieHandles_with_releaseDate = len(movieHandles_with_releaseDate)\n",
    "            print(\"num_movieHandles_with_releaseDate = \" + str(num_movieHandles_with_releaseDate))\n",
    "            print()\n",
    "\n",
    "\n",
    "            movieHandles_releaseDate = [movieHandle_to_movieDoss[h]['02_film_release_date'] for h in movieHandles_with_releaseDate]\n",
    "            movieHandles_releaseDate_min = min(movieHandles_releaseDate)\n",
    "            movieHandles_releaseDate_max = max(movieHandles_releaseDate)\n",
    "            movieHandles_earliest = [h for h in movieHandles_with_releaseDate if \n",
    "                                     movieHandle_to_movieDoss[h]['02_film_release_date'] == movieHandles_releaseDate_min]\n",
    "            movieHandles_latest = [h for h in movieHandles_with_releaseDate if\n",
    "                                   movieHandle_to_movieDoss[h]['02_film_release_date'] == movieHandles_releaseDate_max]\n",
    "            print(\"movieHandles_releaseDate_min = \" + str(movieHandles_releaseDate_min))\n",
    "            print(\"movieHandles_releaseDate_max = \" + str(movieHandles_releaseDate_max))\n",
    "            print(\"movieHandles_earliest = \" + repr(movieHandles_earliest))\n",
    "            print(\"movieHandles_latest = \" + repr(movieHandles_latest))\n",
    "            print()\n",
    "        except:\n",
    "            print(\"skipping movieHandles_releaseDate analysis\")\n",
    "            print()\n",
    "\n",
    "        try:\n",
    "            movieHandles_numBOY = [len(movieHandle_to_movieDoss[h]['boxOfficeYears']) for h in movieHandles_all]\n",
    "            movieHandles_numBOY_min = min(movieHandles_numBOY)\n",
    "            movieHandles_numBOY_max = max(movieHandles_numBOY)\n",
    "            movieHandles_numBOY_highest = [h for h, numBOY in zip(movieHandles_all, movieHandles_numBOY) \n",
    "                                           if numBOY == movieHandles_numBOY_max]\n",
    "            print(\"movieHandles_numBOY_min = \" + str(movieHandles_numBOY_min))\n",
    "            print(\"movieHandles_numBOY_max = \" + str(movieHandles_numBOY_max))\n",
    "            print(\"movieHandles_numBOY_highest = \" + str(movieHandles_numBOY_highest))\n",
    "            for mh in movieHandles_numBOY_highest:\n",
    "                print(\"movieHandle_to_movieDoss[\" + repr(mh) + \"]['boxOfficeYears'] = \")\n",
    "                print(repr(movieHandle_to_movieDoss[mh]['boxOfficeYears']))\n",
    "                print()\n",
    "        except:\n",
    "            print(\"skipping movieHandles_numBOY analysis\")\n",
    "            print()\n",
    "    \n",
    "    # This is a nice way to end program execution, in a Jupyter Notebook\n",
    "    print(\"Purposely Terminating program execution, now.\")\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Follow-on activity:\n",
    "#  Use values stored in the eventHandle_to_eventDoss dictionary\n",
    "#  to populate a pandas dataframe, \"df\"\n",
    "#\n",
    "#  MICHAEL COLLINS, 2020-09-11_2107_MDT\n",
    "\n",
    "\n",
    "# Force seaborn to make the backgrounds of graphs white, instead of transparent\n",
    "# Kudos to my classmate Gustavo Chavez for offering a solution to this problem\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# This deletes the file specified with name strFile, if the file exists.\n",
    "# Then it issues a plt.savefig() to save the current matplotlib to a new\n",
    "# instance of file strFile.\n",
    "def delete_then_plt_savefig(strFile):\n",
    "    if os.path.isfile(strFile):\n",
    "        os.remove(strFile)   # Opt.: os.system(\"rm \"+strFile)\n",
    "    plt.savefig(strFile)\n",
    "    return\n",
    "\n",
    "# Construct a list of all unique event-level keys that will be encountered\n",
    "print(\"All the event-level keys in eventHandle_to_eventDoss, as eventDoss_keys_all:\")\n",
    "keys_sorted = sorted(eventHandle_to_eventDoss.keys())\n",
    "eventDoss_keys_all = []\n",
    "for eh in keys_sorted:\n",
    "    eventDoss = eventHandle_to_eventDoss[eh]\n",
    "    eventDoss_keys = eventDoss.keys()\n",
    "    for k in eventDoss_keys:\n",
    "        if not k in eventDoss_keys_all:\n",
    "            eventDoss_keys_all.append(k)\n",
    "for i, dk in enumerate(eventDoss_keys_all):\n",
    "    print(\"i=\" + str(i) + \", \" + dk)\n",
    "print()\n",
    "\n",
    "# Determine exactly which event-level keys should be ported into the dataframe\n",
    "def keep_eventDoss_key(key):\n",
    "    if key in ['event_handle']:\n",
    "        return False\n",
    "    return True\n",
    "eventDoss_keys_use = [k for k in eventDoss_keys_all if keep_eventDoss_key(k)]\n",
    "\n",
    "# Load the pandas dataframe with desired data from eventHandle_to_eventDoss\n",
    "df = pd.DataFrame.from_dict(eventHandle_to_eventDoss, orient='index', columns=eventDoss_keys_use).fillna(0)\n",
    "print(\"df {initial values, based on eventHandle_to_eventDoss}... \")\n",
    "display(df)\n",
    "print()\n",
    "\n",
    "# These are names of existing (and some possible future) columns within the dataframe\n",
    "col_genre = 'genre_abbr'\n",
    "col_year = 'boxOfficeYear'\n",
    "col_genreYear = \"genreYear_handle\"\n",
    "col_budget = 'productionBudget_adj'\n",
    "col_log10_budget = 'log10_productionBudget_adj'\n",
    "col_boy_domUS_sales = 'boxOfficeYear_domUS_adj'\n",
    "col_log10_boy_domUS_sales = 'log10_boxOfficeYear_domUS_adj'\n",
    "col_world_gross = \"total_world_gross\"\n",
    "col_log10_world_gross = \"log10_total_world_gross\"\n",
    "col_symbol_size = \"symbol_size\"\n",
    "col_genre_num = \"genre_num\"\n",
    "col_sbRatio = \"sbRatio\"\n",
    "col_log10_sbRatio = \"log10_sbRatio\"\n",
    "\n",
    "# These are new columns being added to the dataframe\n",
    "df[col_sbRatio] = df[col_world_gross]/df[col_budget]\n",
    "df[col_log10_sbRatio] = np.log10(df[col_sbRatio])\n",
    "df[col_log10_boy_domUS_sales] = np.log10(df[col_boy_domUS_sales])\n",
    "df[col_log10_budget] = np.log10(df[col_budget])\n",
    "df[col_log10_world_gross] = np.log10(df[col_world_gross])\n",
    "budget_max = np.max(df[col_budget])\n",
    "df[col_symbol_size] = 100*df[col_budget]/budget_max\n",
    "u, df[col_genre_num] = np.unique(df[col_genre], return_inverse=True)\n",
    "\n",
    "# Show the dataframe after the new columns are added\n",
    "print(\"df {after adding new columns}... \")\n",
    "display(df)\n",
    "print()\n",
    "\n",
    "make_IMAGE_1 = True\n",
    "if make_IMAGE_1:\n",
    "    fig, ax = None, None\n",
    "    print(\"making a strip plot... \")\n",
    "    print()\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    sns.stripplot(data=df, y=col_genre, x=col_year, order=TN_GENRE_ABBRS,\n",
    "                  alpha=0.2, jitter=0.25, dodge=True, orient='h', marker=\"o\", s=8)\n",
    "    plt.ylabel(None, size=26)\n",
    "    plt.xlabel(\"Box Office Year\", size=16)\n",
    "    plt.grid()\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlim([1975, 2025])\n",
    "    plt.xticks(np.arange(1975, 2026, 5.0))\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.title(\"Movies by Genre and Box Office Year\", size=20)\n",
    "    plt.tight_layout()\n",
    "    delete_then_plt_savefig(\"DOSFLIX_Movies_by_Genre_and_boxOfficeYear.png\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "make_IMAGE_2 = True\n",
    "if make_IMAGE_2:\n",
    "    fig, ax = None, None\n",
    "    print(\"making [sales vs. boxOfficeYear] scatter plot... \")\n",
    "    print(\"for movies from ALL GENRES combined... \")\n",
    "    print()\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    sc = ax.scatter(data=df, y=col_log10_boy_domUS_sales, x=col_year, c=col_genre_num,\n",
    "                    alpha=0.8, marker=\"o\", s=col_symbol_size)\n",
    "    ax.legend(sc.legend_elements()[0], u)\n",
    "    ax.grid()\n",
    "    ax.set_ylim(ymin=3, ymax=10)\n",
    "    plt.yticks(np.arange(3, 11, 1.0))\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax.set_xlim(xmin=1975, xmax=2025)\n",
    "    plt.xticks(np.arange(1975, 2026, 5.0))\n",
    "    plt.xticks(fontsize=14)\n",
    "    s_title = \"ALL GENRES represented: Log10(Sales) vs. boxOfficeYear\"\n",
    "    plt.title(s_title, size=24)\n",
    "    plt.ylabel('Log10(Annual_US_Sales, ADJUSTED usd)', size=18)\n",
    "    plt.xlabel('Box Office Year', size=18)\n",
    "    fig_saveat = \"DOSFLIX_Annual_US_Sales_vs_boxOfficeYear,ALL_GENRES.png\"\n",
    "    delete_then_plt_savefig(fig_saveat)\n",
    "    plt.show()\n",
    "    for n, grp in df.groupby(col_genre):\n",
    "        fig, ax = None, None\n",
    "        print(\"making [sales vs. boxOfficeYear] scatter plot\")\n",
    "        print(\"for movies from GENRE=\" + str(n) + \", specifically... \")\n",
    "        print()\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        c_n = gAbbr_to_gIndex[n]\n",
    "        c_list = [c_n for i in range(grp.shape[0])]\n",
    "        ax.scatter(data=grp, y=col_log10_boy_domUS_sales, x=col_year,\n",
    "                   alpha=0.8, marker=\"o\", s=col_symbol_size)\n",
    "        ax.legend(title=\"Genre = \" + n)\n",
    "        ax.grid()\n",
    "        ax.set_ylim(ymin=3, ymax=10)\n",
    "        plt.yticks(np.arange(3, 11, 1.0))\n",
    "        plt.yticks(fontsize=14)\n",
    "        ax.set_xlim(xmin=1975, xmax=2025)\n",
    "        plt.xticks(np.arange(1975, 2026, 5.0))\n",
    "        plt.xticks(fontsize=14)\n",
    "        s_title = \"GENRE=\" + str(n) + \": Log10(Sales) vs. boxOfficeYear\"\n",
    "        plt.title(s_title, size=24)\n",
    "        plt.ylabel('Log10(Annual_US_Sales, ADJUSTED usd)', size=18)\n",
    "        plt.xlabel('Box Office Year', size=18)\n",
    "        fig_saveat = \"DOSFLIX_Annual_US_Sales_vs_boxOfficeYear,GENRE=\" + str(n) + \".png\"\n",
    "        delete_then_plt_savefig(fig_saveat)\n",
    "        plt.show()\n",
    "    # the plots generated using delete_then_plt_savefig, above, were \n",
    "    # stitched together into an animated GIF \"manually\" via the website\n",
    "    # https://ezgif.com/\n",
    "\n",
    "\n",
    "make_IMAGE_3 = True\n",
    "if make_IMAGE_3:\n",
    "    fig, ax = None, None\n",
    "    print(\"making [sales vs. budget] scatter plot\")\n",
    "    print(\"for movies from ALL GENRES combined... \")\n",
    "    print()\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    for n, grp in df.groupby(col_genre):\n",
    "    #     print(\"n = \" + repr(n))\n",
    "    #     print(\"grp.shape[0] = \" + repr(grp.shape[0]))\n",
    "        c_n = gAbbr_to_gIndex[n]\n",
    "        c_list = [c_n for i in range(grp.shape[0])]\n",
    "        ax.scatter(data=grp, y=col_log10_world_gross, x=col_log10_budget, label=n, \n",
    "                   alpha=0.8, marker=\",\", s=1)\n",
    "    ax.legend(title=\"Genre\")\n",
    "    plt.ylim([3, 10])\n",
    "    plt.yticks(np.arange(3, 11, 1.0))\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlim([3, 9])\n",
    "    plt.xticks(np.arange(3, 10, 1.0))\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.title(\"ALL GENRES represented: World Gross vs. Budget\", size=24)\n",
    "    plt.ylabel('Log10(TotalWorldwideSales, usd)', size=18)\n",
    "    plt.xlabel('Log10(Production_Budget, ADJUSTED usd)', size=18)\n",
    "    delete_then_plt_savefig(\"DOSFLIX_worldGross_vs_ProdBudget,ALL_GENRES.png\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = None, None\n",
    "    for n, grp in df.groupby(col_genre):\n",
    "        print(\"making [sales vs. budget] scatter plots\")\n",
    "        print(\"for movies from GENRE=\" + str(n) + \", specifically... \")\n",
    "        print()\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        c_n = gAbbr_to_gIndex[n]\n",
    "        c_list = [c_n for i in range(grp.shape[0])]\n",
    "        ax.scatter(data=grp, y=col_log10_world_gross, x=col_log10_budget,\n",
    "                   alpha=0.2, marker=\"o\", s=10)\n",
    "        ax.legend(title=\"Genre = \" + n)\n",
    "        plt.ylim([3, 10])\n",
    "        plt.yticks(np.arange(3, 11, 1.0))\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.xlim([3, 9])\n",
    "        plt.xticks(np.arange(3, 10, 1.0))\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.grid()\n",
    "        s_title = \"GENRE=\" + str(n) + \": World Gross vs. Budget\"\n",
    "        plt.title(s_title, size=24)\n",
    "        plt.ylabel('Log10(TotalWorldwideSales, usd)', size=18)\n",
    "        plt.xlabel('Log10(Production_Budget, ADJUSTED usd)', size=18)\n",
    "\n",
    "        fig_saveat = \"DOSFLIX_worldGross_vs_ProdBudget,GENRE=\" + str(n) + \".png\"\n",
    "        delete_then_plt_savefig(fig_saveat)\n",
    "        plt.show()\n",
    "    # the plots generated using delete_then_plt_savefig, above, were \n",
    "    # stitched together into an animated GIF \"manually\" via the website\n",
    "    # https://ezgif.com/    \n",
    "\n",
    "make_IMAGE_4 = True\n",
    "if make_IMAGE_4:\n",
    "    fig, ax = None, None\n",
    "    print(\"making [sbRatio vs. budget] scatter plot\")\n",
    "    print(\"for movies from ALL GENRES combined... \")\n",
    "    print()\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    for n, grp in df.groupby(col_genre):\n",
    "    #     print(\"n = \" + repr(n))\n",
    "    #     print(\"grp.shape[0] = \" + repr(grp.shape[0]))\n",
    "        c_n = gAbbr_to_gIndex[n]\n",
    "        c_list = [c_n for i in range(grp.shape[0])]\n",
    "        ax.scatter(data=grp, y=col_log10_sbRatio, x=col_log10_budget, label=n, \n",
    "                   alpha=0.8, marker=\",\", s=1)\n",
    "    ax.legend(title=\"Genre\")\n",
    "    plt.ylim([-6, 3])\n",
    "    plt.yticks(np.arange(-6, 4, 1.0))\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlim([3, 9])\n",
    "    plt.xticks(np.arange(3, 10, 1.0))\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.title(\"ALL GENRES represented: sbRatio vs. Budget\", size=24)\n",
    "    plt.ylabel('Log10(TotalWorldwideSales / ProdBudget)', size=18)\n",
    "    plt.xlabel('Log10(Production_Budget, ADJUSTED usd)', size=18)\n",
    "    delete_then_plt_savefig(\"DOSFLIX_sbRatio_vs_ProdBudget,ALL_GENRES.png\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = None, None\n",
    "    for n, grp in df.groupby(col_genre):\n",
    "        print(\"making [sbRatio vs. budget] scatter plots\")\n",
    "        print(\"for movies from GENRE=\" + str(n) + \", specifically... \")\n",
    "        print()\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        c_n = gAbbr_to_gIndex[n]\n",
    "        c_list = [c_n for i in range(grp.shape[0])]\n",
    "        ax.scatter(data=grp, y=col_log10_sbRatio, x=col_log10_budget,\n",
    "                   alpha=0.2, marker=\"o\", s=10)\n",
    "        ax.legend(title=\"Genre = \" + n)\n",
    "        plt.ylim([-6, 3])\n",
    "        plt.yticks(np.arange(-6, 4, 1.0))\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.xlim([3, 9])\n",
    "        plt.xticks(np.arange(3, 10, 1.0))\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.grid()\n",
    "        s_title = \"GENRE=\" + str(n) + \": sbRatio vs. Budget\"\n",
    "        plt.title(s_title, size=24)\n",
    "        plt.ylabel('Log10(TotalWorldwideSales / ProdBudget)', size=18)\n",
    "        plt.xlabel('Log10(Production_Budget, ADJUSTED usd)', size=18)\n",
    "\n",
    "        fig_saveat = \"DOSFLIX_sbRatio_vs_ProdBudget,GENRE=\" + str(n) + \".png\"\n",
    "        delete_then_plt_savefig(fig_saveat)\n",
    "        plt.show()\n",
    "    # the plots generated using delete_then_plt_savefig, above, were \n",
    "    # stitched together into an animated GIF \"manually\" via the website\n",
    "    # https://ezgif.com/\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# That should do it.  Thanks for reading my code.  -- MLC\n",
    "print(\"That's all, Folks!\")\n",
    "\n",
    "do_extra_stuff = False\n",
    "if do_extra_stuff:\n",
    "    # This is extra stuff\n",
    "    # so please don't knock me for lack of commentary\n",
    "    \n",
    "    def inspect(x):\n",
    "        print(repr(type(x)) + \" \" + repr(x))\n",
    "        return -1\n",
    "\n",
    "    def robust_weighted_average(x_i, w_i):\n",
    "        if np.sum(w_i) == 0.0:\n",
    "            return 0.0\n",
    "        return np.average(x_i, weights=w_i)\n",
    "\n",
    "    genre_pb_avg = df.groupby(by=col_genreYear).apply(lambda gb: robust_weighted_average(gb[col_budget], gb[col_boy_domUS_sales])/gb[col_budget].shape[0])\n",
    "    print(\"genre_pb_avg... \")\n",
    "    display(genre_pb_avg)\n",
    "    print()\n",
    "\n",
    "    df[col_pb_avg] = df[col_genreYear].map(genre_pb_avg)\n",
    "    print(\"df {AFTER col_pb_avg was added to df}... \")\n",
    "    display(df)\n",
    "    print()\n",
    "\n",
    "    genre_pb_avg_sum = df.groupby(by=col_genreYear)[col_pb_avg].sum()\n",
    "    print(\"genre_pb_avg_sum... \")\n",
    "    display(genre_pb_avg_sum)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of Project1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
